[{"path":"/articles/vignette.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"BRCindicators","text":"document shows use indicator pipeline create biodiversity indicators DEFRA’s Biodiversity Indicators Pocket. pipeline shared form R package called ‘BRCindicators’ making easy share maintain. functions BRCindicators work yearly estimates species abundance occurrence aggregate scaled indicator value bootstrapped confidence intervals package ability read output occupancy models created R package sparta, package estimating species trends occurrence data. package can installed Github details use package given package vignette. need use sparta create yearly species estimates BRCindicators can also work data. create indicator first need species trends, let’s create using sparta R package.","code":""},{"path":"/articles/vignette.html","id":"creating-yearly-estimates-of-occurrence-in-sparta","dir":"Articles","previous_headings":"","what":"Creating yearly estimates of occurrence in sparta","title":"BRCindicators","text":"already yearly estimates abundance occurrence species can skip stage. show can create estimates raw species observation data using sparta. Let’s assume raw data already, can take occupancy modelling like demonstration purposes faked dataset 8000 species observations. dataset species named letters alphabet. show can use Bayesian occupancy models sparta create yearly estimates occurrence. information please see vignette sparta","code":"# Install BRCindicators from github library(devtools) #install_github('biologicalrecordscentre/sparta') # Create data n <- 8000 # size of dataset nyr <- 50 # number of years in data nSamples <- 200 # set number of dates nSites <- 100 # set number of sites set.seed(125) # set a random seed  # Create somes dates first <- as.Date(strptime(\"1950/01/01\", \"%Y/%m/%d\"))  last <- as.Date(strptime(paste(1950+(nyr-1),\"/12/31\", sep=''), \"%Y/%m/%d\"))  dt <- last-first  rDates <- first + (runif(nSamples)*dt)  # taxa are set semi-randomly taxa_probabilities <- seq(from = 0.1, to = 0.7, length.out = 26) taxa <- sample(letters, size = n, TRUE, prob = taxa_probabilities)  # sites are visited semi-randomly site_probabilities <- seq(from = 0.1, to = 0.7, length.out = nSites) site <- sample(paste('A', 1:nSites, sep=''), size = n, TRUE, prob = site_probabilities)  # the date of visit is selected semi-randomly from those created earlier time_probabilities <- seq(from = 0.1, to = 0.7, length.out = nSamples) time_period <- sample(rDates, size = n, TRUE, prob = time_probabilities)  myData <- data.frame(taxa, site, time_period) # Load the sparta package library(sparta) # Preview of my data head(myData) ##   taxa site time_period ## 1    r  A51  1970-01-14 ## 2    v  A87  1980-09-29 ## 3    e  A56  1996-04-14 ## 4    z  A28  1959-01-16 ## 5    r  A77  1970-09-21 ## 6    x  A48  1990-02-25 # First format our data formattedOccData <- formatOccData(taxa = myData$taxa,                                   site = myData$site,                                   survey = myData$time_period) ## Warning in errorChecks(taxa = taxa, site = site, survey = survey, replicate = ## replicate, : 94 out of 8000 observations will be removed as duplicates # Here we are going to use the package snowfall to parallelise library(snowfall)  # I have 4 cpus on my PC so I set cpus to 4 # when I initialise the cluster sfInit(parallel = TRUE, cpus = 4) ## R Version:  R version 4.4.0 (2024-04-24 ucrt) ## snowfall 1.84-6.3 initialized (using snow 0.4-4): parallel execution on 4 CPUs. # Export my data to the cluster sfExport('formattedOccData')  # I create a function that takes a species name and runs my model occ_mod_function <- function(taxa_name){      library(sparta)      # Note that this will write you results to your computer   # the location is set to your user folder   occ_out <- occDetFunc(taxa_name = as.character(taxa_name),                         n_iterations = 200,                         burnin = 15,                          occDetdata = formattedOccData$occDetdata,                         spp_vis = formattedOccData$spp_vis,                         write_results = TRUE,                         output_dir = '~/Testing_indicator_pipe',                         seed = 123)   }  # I then run this in parallel system.time({ para_out <- sfClusterApplyLB(unique(myData$taxa), occ_mod_function) }) ##    user  system elapsed  ##    0.06    0.07  162.00 # Stop the cluster sfStop() ##  ## Stopping cluster # We can see all the files this has created list.files('~/Testing_indicator_pipe') ##  [1] \"a.rdata\" \"b.rdata\" \"c.rdata\" \"d.rdata\" \"e.rdata\" \"f.rdata\" \"g.rdata\" ##  [8] \"h.rdata\" \"i.rdata\" \"j.rdata\" \"k.rdata\" \"l.rdata\" \"m.rdata\" \"n.rdata\" ## [15] \"o.rdata\" \"p.rdata\" \"q.rdata\" \"r.rdata\" \"s.rdata\" \"t.rdata\" \"u.rdata\" ## [22] \"v.rdata\" \"w.rdata\" \"x.rdata\" \"y.rdata\" \"z.rdata\""},{"path":"/articles/vignette.html","id":"installing-brcindicators","dir":"Articles","previous_headings":"","what":"Installing BRCindicators","title":"BRCindicators","text":"Installing package easy can done couple lines","code":"library(devtools)  install_github('biologicalrecordscentre/BRCindicators')"},{"path":"/articles/vignette.html","id":"summarising-sparta-output-for-an-indicator","dir":"Articles","previous_headings":"","what":"Summarising sparta output for an indicator","title":"BRCindicators","text":"Now species trends data work (doubt already ) can use first function BRCindicators. function reads output files sparta (quite large complex) returns simple summary table can use calculating indicator. done analysis without using sparta can skip next step. Returned function summary data matrix. row year, specified first column, subsequent column species. values table mean posterior predicted proportion sites occupied, measure occurrence.","code":"library(BRCindicators)  # All we have to supply is the directory where out data is saved # You will note this is the 'output_dir' passed to sparta above. trends_summary <- summarise_occDet(input_dir = '~/Testing_indicator_pipe') ## Loading data...done # Lets see the summary head(trends_summary[,1:5]) ##      year          a         b         c         d ## [1,] 1950 0.71950820 0.7444262 0.5445902 0.7289617 ## [2,] 1951 0.64792350 0.7115847 0.6653552 0.5564481 ## [3,] 1952 0.61234973 0.6830055 0.2850820 0.5503279 ## [4,] 1953 0.47890710 0.4786339 0.5400546 0.6146448 ## [5,] 1954 0.40245902 0.5300546 0.6093443 0.4449180 ## [6,] 1955 0.04765027 0.4463934 0.6180874 0.3305464"},{"path":"/articles/vignette.html","id":"calculating-indicator-values","dir":"Articles","previous_headings":"","what":"Calculating indicator values","title":"BRCindicators","text":"species-year indicies position proceed calculating indictor. number mehods available, presented ‘BRCindicators’","code":""},{"path":"/articles/vignette.html","id":"geometric-mean","dir":"Articles","previous_headings":"Calculating indicator values","what":"Geometric mean","title":"BRCindicators","text":"geometric mean method often used data errors associated . first step re-scale data value species first year . done calculate geometric mean across species year creating indicator value. function also accounts species data beginning dataset entering geometric mean year, stops dramatically changing indicator value year join dataset. also accounts species leave dataset end holding last value. Finally limits species values can given, preventing extremely high low values biasing indicator.","code":""},{"path":"/articles/vignette.html","id":"rescaling-and-calculating-geometric-mean","dir":"Articles","previous_headings":"Calculating indicator values > Geometric mean","what":"Rescaling and calculating geometric mean","title":"BRCindicators","text":"data generated ‘trends_summary’ easy work show function can ’m going mess bit. Now ‘messed ’ data bit two species data missing beginning one species data missing end. also one species high values. Now lets run re-scaling function. can see species ‘’ ‘b’ enter dataset geometric mean (indicator value), species indexed 100 first year high values ‘c’ capped 10000 end ‘d’ held ’s end value. ‘indicator’ column returned indicator, calculated geometric mean species data set.","code":"trends_summary[1:3, 'a'] <- NA trends_summary[1:5, 'b'] <- NA trends_summary[2:4, 'c'] <- 1000 trends_summary[45:50, 'd'] <- NA  # Let's have a look at these changes head(trends_summary[,1:5]) ##      year          a         b            c         d ## [1,] 1950         NA        NA    0.5445902 0.7289617 ## [2,] 1951         NA        NA 1000.0000000 0.5564481 ## [3,] 1952         NA        NA 1000.0000000 0.5503279 ## [4,] 1953 0.47890710        NA 1000.0000000 0.6146448 ## [5,] 1954 0.40245902        NA    0.6093443 0.4449180 ## [6,] 1955 0.04765027 0.4463934    0.6180874 0.3305464 tail(trends_summary[,1:5]) ##       year         a         b         c  d ## [45,] 1994 0.3276503 0.5717486 0.1508743 NA ## [46,] 1995 0.5151913 0.4853552 0.6555738 NA ## [47,] 1996 0.4673224 0.4795628 0.4220765 NA ## [48,] 1997 0.3340984 0.6895628 0.7624590 NA ## [49,] 1998 0.6545355 0.1724044 0.3939891 NA ## [50,] 1999 0.5532787 0.3660656 0.7278142 NA # Let's run this data through our scaling function (all defaults used) rescaled_trends <- rescale_species(Data = trends_summary)  # Here's the result head(rescaled_trends[,c('year', 'indicator', 'a', 'b', 'c', 'd')]) ##      year indicator         a        b          c         d ## [1,] 1950 100.00000        NA       NA   100.0000 100.00000 ## [2,] 1951 113.66130        NA       NA 10000.0000  76.33433 ## [3,] 1952 124.43795        NA       NA 10000.0000  75.49475 ## [4,] 1953 112.24009 112.24009       NA 10000.0000  84.31784 ## [5,] 1954  92.53638  94.32317       NA   111.8904  61.03448 ## [6,] 1955  94.92278  11.16766 94.92278   113.4959  45.34483 tail(rescaled_trends[,c('year', 'indicator', 'a', 'b', 'c', 'd')]) ##       year indicator         a         b         c        d ## [45,] 1994  94.69719  76.79046 121.57878  27.70419 96.72414 ## [46,] 1995 109.25300 120.74391 103.20775 120.37929 96.72414 ## [47,] 1996 103.80961 109.52502 101.97604  77.50351 96.72414 ## [48,] 1997 110.66363  78.30168 146.63123 140.00602 96.72414 ## [49,] 1998  93.88742 153.40162  36.66071  72.34598 96.72414 ## [50,] 1999 100.38848 129.67035  77.84156 133.64439 96.72414"},{"path":"/articles/vignette.html","id":"confidence-intervals","dir":"Articles","previous_headings":"Calculating indicator values > Geometric mean","what":"Confidence intervals","title":"BRCindicators","text":"can get confidence intervals indicator bootstrapping across species. function !","code":"# This function takes just the species columns scaled_species <- rescaled_trends[,!colnames(rescaled_trends) %in% c('year', 'indicator')] indicator_CIs <- bootstrap_indicator(Data = scaled_species) ##   |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |==                                                                    |   4%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |==============================                                        |  44%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |=====================================                                 |  54%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  55%  |                                                                              |=======================================                               |  56%  |                                                                              |========================================                              |  56%  |                                                                              |========================================                              |  57%  |                                                                              |========================================                              |  58%  |                                                                              |=========================================                             |  58%  |                                                                              |=========================================                             |  59%  |                                                                              |==========================================                            |  59%  |                                                                              |==========================================                            |  60%  |                                                                              |==========================================                            |  61%  |                                                                              |===========================================                           |  61%  |                                                                              |===========================================                           |  62%  |                                                                              |============================================                          |  62%  |                                                                              |============================================                          |  63%  |                                                                              |============================================                          |  64%  |                                                                              |=============================================                         |  64%  |                                                                              |=============================================                         |  65%  |                                                                              |==============================================                        |  65%  |                                                                              |==============================================                        |  66%  |                                                                              |===============================================                       |  66%  |                                                                              |===============================================                       |  67%  |                                                                              |===============================================                       |  68%  |                                                                              |================================================                      |  68%  |                                                                              |================================================                      |  69%  |                                                                              |=================================================                     |  69%  |                                                                              |=================================================                     |  70%  |                                                                              |=================================================                     |  71%  |                                                                              |==================================================                    |  71%  |                                                                              |==================================================                    |  72%  |                                                                              |===================================================                   |  72%  |                                                                              |===================================================                   |  73%  |                                                                              |===================================================                   |  74%  |                                                                              |====================================================                  |  74%  |                                                                              |====================================================                  |  75%  |                                                                              |=====================================================                 |  75%  |                                                                              |=====================================================                 |  76%  |                                                                              |======================================================                |  76%  |                                                                              |======================================================                |  77%  |                                                                              |======================================================                |  78%  |                                                                              |=======================================================               |  78%  |                                                                              |=======================================================               |  79%  |                                                                              |========================================================              |  79%  |                                                                              |========================================================              |  80%  |                                                                              |========================================================              |  81%  |                                                                              |=========================================================             |  81%  |                                                                              |=========================================================             |  82%  |                                                                              |==========================================================            |  82%  |                                                                              |==========================================================            |  83%  |                                                                              |==========================================================            |  84%  |                                                                              |===========================================================           |  84%  |                                                                              |===========================================================           |  85%  |                                                                              |============================================================          |  85%  |                                                                              |============================================================          |  86%  |                                                                              |=============================================================         |  86%  |                                                                              |=============================================================         |  87%  |                                                                              |=============================================================         |  88%  |                                                                              |==============================================================        |  88%  |                                                                              |==============================================================        |  89%  |                                                                              |===============================================================       |  89%  |                                                                              |===============================================================       |  90%  |                                                                              |===============================================================       |  91%  |                                                                              |================================================================      |  91%  |                                                                              |================================================================      |  92%  |                                                                              |=================================================================     |  92%  |                                                                              |=================================================================     |  93%  |                                                                              |=================================================================     |  94%  |                                                                              |==================================================================    |  94%  |                                                                              |==================================================================    |  95%  |                                                                              |===================================================================   |  95%  |                                                                              |===================================================================   |  96%  |                                                                              |====================================================================  |  96%  |                                                                              |====================================================================  |  97%  |                                                                              |====================================================================  |  98%  |                                                                              |===================================================================== |  98%  |                                                                              |===================================================================== |  99%  |                                                                              |======================================================================|  99%  |                                                                              |======================================================================| 100% # Returned are the CIs for our indicator head(indicator_CIs) ##      quant_025 quant_975 ## [1,] 100.00000  100.0000 ## [2,]  79.51664  185.3712 ## [3,]  92.57867  197.7989 ## [4,]  71.91175  186.9973 ## [5,]  76.48790  111.0772 ## [6,]  74.68679  116.8558"},{"path":"/articles/vignette.html","id":"smoothing","dir":"Articles","previous_headings":"Calculating indicator values > Geometric mean","what":"Smoothing","title":"BRCindicators","text":"sometimes desirable create smoothed indicator value raw values. can achieved fitting GAM (general additive model) indicator using spline. spline smoothed curve goes raw values indicator fitted using function ‘gam’ ‘mgcv’ R package.   little support non-linear trend GAM smoothed line tend towards linear. good support non-linear trend smoothed line become ‘bendy’.","code":"# The smoothing function takes the indicator values smoothed_indicator <- GAM_smoothing(rescaled_trends[,'indicator'])  # In this example there is little support for a non-linear trend and  # so the line almost linear plot(x = rescaled_trends[,'year'], y = rescaled_trends[,'indicator']) lines(x = rescaled_trends[,'year'], y = smoothed_indicator, col = 'red') # But if our indicator did support a non-linear trend it might look  # like this eg_indicator <- jitter(sort(rnorm(50)), amount = 0.5) eg_smoothed <- GAM_smoothing(eg_indicator) plot(x = 1:50, y = eg_indicator) lines(x = 1:50, y = eg_smoothed, col = 'red')"},{"path":"/articles/vignette.html","id":"plotting","dir":"Articles","previous_headings":"Calculating indicator values > Geometric mean","what":"Plotting","title":"BRCindicators","text":"now indicator confidence intervals around . next step plot . included function creates simple plot using ggplot2, however easily create plots R using data.  plot can see high upper confidence interval years 2-4, due artificially high values gave species ‘c’.","code":"# Plot our indicator. plot_indicator(indicator = rescaled_trends[,'indicator'],                smoothed_line = smoothed_indicator,                CIs = indicator_CIs)"},{"path":"/articles/vignette.html","id":"bayesian-meta-analysis-bma","dir":"Articles","previous_headings":"Calculating indicator values","what":"Bayesian Meta-Analysis (BMA)","title":"BRCindicators","text":"Bayesian Meta-Analysis method, BMA, suited data standard errors associated . methods require data one species, across number years, error species-year estimate. important data format columns order names. Remember can use function read.csv() read data .csv computer. BMA run using function bma, use default settings see can change.  function returns plot screen diagnostic plot model. model converged (.e. reached point three chains agree answer) lines plots left sit top one another plots right nice bell shape. can turn plot setting plot FALSE. default method runs chains series. Running parallel makes models run faster (half time) slow computer . can change parameter parallel. number iterations model runs controlled n.iter defaults 10000. can better run iterations, though take longer. m.scale gives scale data . important correct, choose ‘loge’ (natural log, sometimes simply called ‘log’), ‘log10’ (log base 10), ‘logit’ (output models proportions probabilities). Let’s implement changes  reduced number interations model longer good convergence. lines graphs left overlap graphs right longer smooth bell shape. object returned data.frame years rows columns giving year value, index value confidence intervals. can write csv using function write.csv. can use plotting function BRCindicators plot results analysis, case interesting!","code":"# Here is an example dataset for the BMA method data <- data.frame(species = rep(letters, each = 50),                    year = rep(1:50, length(letters)),                     index = runif(n = 50 * length(letters), min = 0, max = 1),                     se = runif(n = 50 * length(letters), min = 0.01, max = .1)) head(data) ##   species year     index         se ## 1       a    1 0.4783269 0.02657337 ## 2       a    2 0.4443901 0.08308297 ## 3       a    3 0.9653410 0.07088607 ## 4       a    4 0.2612954 0.06101668 ## 5       a    5 0.7607192 0.04758781 ## 6       a    6 0.7500249 0.01699128 bma_indicator <- bma(data) ## [1] \"Warning: No negative index values detected. Are you sure you transformed the data?\" ##  ## Processing function input.......  ##  ## Done.  ##   ## Compiling model graph ##    Resolving undeclared variables ##    Allocating nodes ## Graph information: ##    Observed stochastic nodes: 1274 ##    Unobserved stochastic nodes: 1291 ##    Total graph size: 8158 ##  ## Initializing model ##  ## Adaptive phase.....  ## Adaptive phase complete  ##   ##  ##  Burn-in phase, 5000 iterations x 3 chains  ##   ##  ## Sampling from joint posterior, 5000 iterations x 3 chains  ##   ##  ## Calculating statistics.......  ##  ## Done. bma_indicator2 <- bma(data,                      parallel = TRUE,                      n.iter = 500,                      m.scale = 'log10') ## [1] \"Warning: No negative index values detected. Are you sure you transformed the data?\" ##  ## Processing function input.......  ##  ## Done.  ##   ## Beginning parallel processing using 11 cores. Console output will be suppressed. ##  ## Parallel processing completed. ##  ## Calculating statistics.......  ##  ## Done. head(bma_indicator) ##   Year Index.Mprime lowerCI.Mprime upperCI.Mprime   Index.M lowerCI.M upperCI.M ## 1    1    100.00000      100.00000       100.0000 100.00000 100.00000  100.0000 ## 2    2     99.28257       96.55888       101.9275  99.36687  96.95978  101.7398 ## 3    3     98.70232       94.93140       102.6840  98.96504  94.93866  103.0453 ## 4    4     98.33416       93.95436       102.8283  98.76247  93.68349  104.0300 ## 5    5     98.37354       93.83166       103.2512  98.72980  92.84002  104.7310 ## 6    6     98.82353       94.46779       103.5405  98.83989  92.47682  105.3083 plot_indicator(indicator = bma_indicator[,'Index.M'],                CIs = bma_indicator[,c(3,4)])"},{"path":"/articles/vignette.html","id":"multi-species-indicator","dir":"Articles","previous_headings":"Calculating indicator values","what":"Multi-species Indicator","title":"BRCindicators","text":"multi-species indicator method developed Statistics Netherlands code made available website. find inner working method please read detailed documentation authors website. simple example method runs BRCindicators.    code returns two plots console, first plot shows coefficient variation (CV) species. Species high values CV may adversly effect relaibility trend estimation. Use graph identify CV values species use maxCV parameter set threshold species excluded. results excluding species way can tested comparing trend plots. CV values hard assign species plot species coded numbers. see raw values look CV component msi_out (.e. msi_out$CV). second plot shows smoothed trend MSI values. two figures can captured usual way R using pdf() example. example create dataset random numbers usually use read.csv() read data local file. second example sets additional parameters. parameters msi get passed msi_tool see list parameters can change look help documentation msi_tool usign ?msi_tool R console. cover hte important ones .  set parameters unrealistic shows options available. Note second graph year 10 point now se = 0, year 15 MSI set 100, short term trend reported last 5 years. analysis also returns data provide insights analysis let create plots required. first two elements (results) returned gives data, little , presented second figure. second element (trends) returned give summary various trend assessments across time series. also added plot method MSI output provides plot similar second figure seen already. Lets use plot method explore effect changing span value analysis  value span gets closer 1 trend line gets smoother.","code":"# Create some example data in the format required nyr = 20 species = rep(letters, each = nyr) year = rev(rep(1:nyr, length(letters)))  # Create an index value that increases with time index = rep(seq(50, 100, length.out = nyr), length(letters)) # Add randomness to species index = index * runif(n = length(index), 0.7, 1.3) # Add correlated randomness across species, to years index = index * rep(runif(0.8, 1.2, n = nyr), length(letters))  se = runif(n = nyr * length(letters), min = 10, max = 20)  data <- data.frame(species, year, index, se)  # Our species are decreasing plot(data$year, data$index) # Species index values need to be 100 in the base year. Here I use # the first year as my base year and rescale to 100. The standard error # in the base year should be 0. min_year <- min(data$year)  for(sp in unique(data$species)){    subset_data <- data[data$species == sp, ]   multi_factor <- 100 / subset_data$index[subset_data$year == min_year]   data$index[data$species == sp] <- data$index[data$species == sp] * multi_factor   data$se[data$species == sp] <- data$se[data$species == sp] * multi_factor   data$se[data$species == sp][1] <- 0  }  # Our first year is now indexed at 100 plot(data$year, data$index) # Alternativly I could read in data from a csv # data <- read.csv('path/to/my/data.csv')  # Run the MSI function msi_out <- msi(data) head(msi_out$CV) ##   species   mean_CV ## 1       a 0.2073205 ## 2       b 0.2097742 ## 3       c 0.2327759 ## 4       d 0.2181222 ## 5       e 0.2148589 ## 6       f 0.2171923 # I can capture the output figures too # pdf('test.pdf') #   msi_out <- msi(data) # dev.off() msi_out <- msi(data,                nsim = 500, # The number of Mote Carlo simulations                SEbaseyear = 10, # The year to index on                plotbaseyear = 15, # The year to set as 100 in plots                index_smoot = 'INDEX', # plotbaseyear uses MSI not trend                span = 0.7, # 'wigglyness' of line, between 0 and 1                lastyears = 5, # last X years of time series for short-term trends                maxCV = 10, # maximum allowed Coefficient of Variation                 changepoint = 10, # compare trends before and after this year                truncfac = 8, # max year-to-year index ratio                TRUNC = 5, #set all indices below TRUNC to this                plot = TRUE # should the plots be returned?)                ) # The returned object has 2 elements head(msi_out$results) ##   year    MSI sd_MSI lower_CL_MSI upper_CL_MSI  Trend lower_CL_trend ## 1    1 174.55   8.59       158.52       192.22 165.98         153.83 ## 2    2 160.34   7.87       145.63       176.55 172.92         164.98 ## 3    3 189.88   9.07       172.92       208.52 177.94         171.72 ## 4    4 169.84   9.00       153.08       188.44 180.72         173.44 ## 5    5 164.29   9.15       147.30       183.24 180.97         173.44 ## 6    6 198.95   9.07       181.95       217.54 179.10         171.72 ##   upper_CL_trend      trend_class ## 1         178.73 moderate_decline ## 2         182.34 moderate_decline ## 3         184.17 moderate_decline ## 4         187.89 moderate_decline ## 5         187.89 moderate_decline ## 6         187.89 moderate_decline # The returned object has 2 elements msi_out$trends ##                             Measure    value     significance ## 1                     overall trend   0.9633 moderate decline ## 2                  SE overall trend   0.0021                  ## 3                trend last 5 years   0.9359 moderate decline ## 4             SE trend last 5 years   0.0166                  ## 5                  changepoint (10)  10.0000                  ## 6     trend before changepoint (10)   0.9891 moderate decline ## 7  SE trend before changepoint (10)   0.0048                  ## 8      trend after changepoint (10)   0.9621 moderate decline ## 9   SE trend after changepoint (10)   0.0045                  ## 10                         % change -43.3920           p<0.01 ## 11                      SE % change   3.0630                  ## 12            % change last 5 years  -9.6510           p<0.01 ## 13         SE % change last 5 years   2.5580                  ## 14                      changepoint       NA           p<0.01 # I could write this as a csv too # write.csv(msi_out$trends, file = 'path/to/my/output.csv') for(i in c(0.3, 0.5, 0.7)){ # use a range of values for span      msi_out <- msi(data, span = i, # span is set to i                  nsim = 200, plot = FALSE)   print( # print makes the plot visible in the for loop     plot(msi_out, title = paste('MSI - span =', i)) # plot   )    }"},{"path":"/articles/vignette.html","id":"lambda-indicator","dir":"Articles","previous_headings":"Calculating indicator values","what":"Lambda Indicator","title":"BRCindicators","text":"lambda indicator calculates indicator using growth rates one year next. Formulating indicator terms growth rates two distinct advantages conventional approach constructing indicators. First, means categorisation species ‘increasing’ ‘decreasing’ can made set data (growth rates) construction indicator. Second, provides elegant solution problem species join indicator first year (.e. first year unreliable): indicators typically adopt complicated rescaling approach ensure species entering indicator first year bias overall assessment. also makes simple robust, though untestable, assumption species drop indicator prior final year: specifically assumes fluctuations , aggregate, species remain indicator. details see http://webarchive.nationalarchives.gov.uk/20170302170037/http://jncc.defra.gov.uk/Docs/UKBI2015_TechBG_C4b-D1c_Bayesian_Final.docx species’ models produced reliable occupancy estimates every year, majority time series contain missing values. presents problem estimating growth rates species-year combination. Missing values growth rate equivalent linear interpolation log odds adjacent years reliable estimates therefore calculated. indicator can therefore work missing values. Input data occupancy scale, therefore bounded 0 1. lambda_indicator takes array data, three-dimensional matrix. dimensions array represent species, years, iterations. row represents species column year. third dimension array contains iterations. Essentially slice contains occupancy estimates species year combination single iteration overall array contains many slices iterations.  number options available lambda_indicator function  Note range threshold functions allow adjust data points used indicator. options remove species year estimates based standard deviaction, Rhat value based number years species present dataset. Note Rhat threshold can used using directory path input rather array.","code":"# number of species nsp = 50  # number of years nyr = 40  #number of iterations iter = 500  # Build a random set of data myArray <- array(data = rnorm(n = nsp*nyr*iter,                                mean = 0.5,                                sd = 0.1),                   dim = c(nsp, nyr, iter),                   dimnames = list(paste0('SP',1:nsp),                                   1:nyr,                                   1:iter))  # Ensure values are bounded by 0 and 1 myArray[myArray > 1] <- 1 myArray[myArray < 0] <- 0  str(myArray) ##  num [1:50, 1:40, 1:500] 0.501 0.44 0.454 0.309 0.307 ... ##  - attr(*, \"dimnames\")=List of 3 ##   ..$ : chr [1:50] \"SP1\" \"SP2\" \"SP3\" \"SP4\" ... ##   ..$ : chr [1:40] \"1\" \"2\" \"3\" \"4\" ... ##   ..$ : chr [1:500] \"1\" \"2\" \"3\" \"4\" ... # Run the lambda_interpolation method on this data myIndicator <- lambda_indicator(myArray)  # Plot the indicator plot_indicator(myIndicator$summary[,'indicator'],                myIndicator$summary[,c('lower' ,'upper')]) myIndicator <- lambda_indicator(myArray,                                 index = 1, # Set the index value to 1 not 100                                 year_range = c(30,40), # Set year range                                 threshold_yrs = 5) # set a threshold plot_indicator(myIndicator$summary[,'indicator'],                myIndicator$summary[,c('lower' ,'upper')])"},{"path":"/articles/vignette.html","id":"creating-a-custom-pipeline-function","dir":"Articles","previous_headings":"","what":"Creating a custom pipeline function","title":"BRCindicators","text":"demonstrated might run indicator functions one time, however ‘pipeline’ want data flow seamlessly. Additionally number parameters functions shown might find useful. example can create pipeline function. function wrap around functions described , setting parameters meet needs. done allow use execute pipeline one line. created function can run pipeline directory one line, put loop run across many directories.","code":"# I call my function 'run_pipeline' and the only arguement it # takes is the directory of sparta's output run_pipeline <- function(input_dir){    require(sparta)   require(BRCindicators)      # Create the trends summary   trends_summary <- summarise_occDet(input_dir = input_dir)    # Rescale the values and get the indicator values   # Here I set the index to 1 and change the value limits   rescaled_trends <- rescale_species(Data = trends_summary,                                      index = 1,                                      max = 100,                                      min = 0.001)      # Bootstrap the indicator to get CIs   scaled_species <- rescaled_trends[,!colnames(rescaled_trends) %in% c('year', 'indicator')]   # This time I set the iterations to twice the default and    # use custom confidence intervals   indicator_CIs <- bootstrap_indicator(Data = scaled_species,                                        CI_limits = c(0.25, 0.75),                                        iterations = 20000)      # Get the smoothed indicator line   smoothed_indicator <- GAM_smoothing(rescaled_trends[,'indicator'])      # This time I specify the years and index value   plot_indicator(indicator = rescaled_trends[,'indicator'],                  year = rescaled_trends[,'year'],                  index = 1,                  CIs = indicator_CIs,                  smoothed_line = smoothed_indicator)      ## I'll return all my data     return(cbind(smoothed_indicator, indicator_CIs, as.data.frame(trends_summary)))  } # Now we can run the pipeline in one line, like a boss indicator_data <- run_pipeline(input_dir = '~/Testing_indicator_pipe') ## Loading data...done ##   |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |==                                                                    |   4%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |==============================                                        |  44%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |=====================================                                 |  54%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  55%  |                                                                              |=======================================                               |  56%  |                                                                              |========================================                              |  56%  |                                                                              |========================================                              |  57%  |                                                                              |========================================                              |  58%  |                                                                              |=========================================                             |  58%  |                                                                              |=========================================                             |  59%  |                                                                              |==========================================                            |  59%  |                                                                              |==========================================                            |  60%  |                                                                              |==========================================                            |  61%  |                                                                              |===========================================                           |  61%  |                                                                              |===========================================                           |  62%  |                                                                              |============================================                          |  62%  |                                                                              |============================================                          |  63%  |                                                                              |============================================                          |  64%  |                                                                              |=============================================                         |  64%  |                                                                              |=============================================                         |  65%  |                                                                              |==============================================                        |  65%  |                                                                              |==============================================                        |  66%  |                                                                              |===============================================                       |  66%  |                                                                              |===============================================                       |  67%  |                                                                              |===============================================                       |  68%  |                                                                              |================================================                      |  68%  |                                                                              |================================================                      |  69%  |                                                                              |=================================================                     |  69%  |                                                                              |=================================================                     |  70%  |                                                                              |=================================================                     |  71%  |                                                                              |==================================================                    |  71%  |                                                                              |==================================================                    |  72%  |                                                                              |===================================================                   |  72%  |                                                                              |===================================================                   |  73%  |                                                                              |===================================================                   |  74%  |                                                                              |====================================================                  |  74%  |                                                                              |====================================================                  |  75%  |                                                                              |=====================================================                 |  75%  |                                                                              |=====================================================                 |  76%  |                                                                              |======================================================                |  76%  |                                                                              |======================================================                |  77%  |                                                                              |======================================================                |  78%  |                                                                              |=======================================================               |  78%  |                                                                              |=======================================================               |  79%  |                                                                              |========================================================              |  79%  |                                                                              |========================================================              |  80%  |                                                                              |========================================================              |  81%  |                                                                              |=========================================================             |  81%  |                                                                              |=========================================================             |  82%  |                                                                              |==========================================================            |  82%  |                                                                              |==========================================================            |  83%  |                                                                              |==========================================================            |  84%  |                                                                              |===========================================================           |  84%  |                                                                              |===========================================================           |  85%  |                                                                              |============================================================          |  85%  |                                                                              |============================================================          |  86%  |                                                                              |=============================================================         |  86%  |                                                                              |=============================================================         |  87%  |                                                                              |=============================================================         |  88%  |                                                                              |==============================================================        |  88%  |                                                                              |==============================================================        |  89%  |                                                                              |===============================================================       |  89%  |                                                                              |===============================================================       |  90%  |                                                                              |===============================================================       |  91%  |                                                                              |================================================================      |  91%  |                                                                              |================================================================      |  92%  |                                                                              |=================================================================     |  92%  |                                                                              |=================================================================     |  93%  |                                                                              |=================================================================     |  94%  |                                                                              |==================================================================    |  94%  |                                                                              |==================================================================    |  95%  |                                                                              |===================================================================   |  95%  |                                                                              |===================================================================   |  96%  |                                                                              |====================================================================  |  96%  |                                                                              |====================================================================  |  97%  |                                                                              |====================================================================  |  98%  |                                                                              |===================================================================== |  98%  |                                                                              |===================================================================== |  99%  |                                                                              |======================================================================|  99%  |                                                                              |======================================================================| 100% head(indicator_data) ##   smoothed_indicator  quant_25  quant_75 year          a         b         c ## 1          0.9176004 1.0000000 1.0000000 1950 0.71950820 0.7444262 0.5445902 ## 2          0.9180913 0.8852408 1.0106197 1951 0.64792350 0.7115847 0.6653552 ## 3          0.9185822 0.9424826 1.0381675 1952 0.61234973 0.6830055 0.2850820 ## 4          0.9190731 0.8238429 1.0059378 1953 0.47890710 0.4786339 0.5400546 ## 5          0.9195640 0.8421503 0.9556367 1954 0.40245902 0.5300546 0.6093443 ## 6          0.9200549 0.8428048 1.0049734 1955 0.04765027 0.4463934 0.6180874 ##           d         e         f         g          h         i         j ## 1 0.7289617 0.5140437 0.5191257 0.6771585 0.77109290 0.3362842 0.6269399 ## 2 0.5564481 0.4214208 0.6875956 0.6949180 0.15005464 0.5807104 0.6743716 ## 3 0.5503279 0.4503825 0.4346995 0.8420765 0.75590164 0.7197268 0.4124590 ## 4 0.6146448 0.4059563 0.7480874 0.4806557 0.02382514 0.8195082 0.7612022 ## 5 0.4449180 0.8789071 0.8591257 0.3380874 0.49256831 0.4837705 0.6448634 ## 6 0.3305464 0.8898907 0.6350820 0.8497814 0.81546448 0.1274863 0.5738251 ##           k         l         m         n         o         p         q ## 1 0.6919126 0.7751366 0.4428415 0.9062295 0.5555191 0.3422404 0.8508743 ## 2 0.3614754 0.7466667 0.7452459 0.8836066 0.9113661 0.7820219 0.3772131 ## 3 0.8724590 0.6345902 0.6355191 0.6290710 0.7693443 0.6283607 0.8969399 ## 4 0.6209836 0.6358470 0.8611475 0.9265027 0.7610929 0.4493989 0.9014754 ## 5 0.3384153 0.7289617 0.5253552 0.7102186 0.9492896 0.7979781 0.8237158 ## 6 0.5411475 0.7955191 0.8191257 0.8801639 0.9270492 0.9244262 0.6891803 ##           r         s         t         u         v         w         x ## 1 0.3624590 0.8491257 0.9315847 0.8820765 0.7602186 0.9207650 0.8680328 ## 2 0.7379235 0.6858470 0.4902732 0.9032240 0.6163388 0.8891803 0.7600546 ## 3 0.8562295 0.8755738 0.5028415 0.9459563 0.6913115 0.6890710 0.7570492 ## 4 0.6147541 0.8377049 0.9469945 0.7153552 0.9408743 0.7243169 0.8547541 ## 5 0.4848634 0.3191803 0.9298361 0.3034426 0.8632787 0.8720765 0.4791257 ## 6 0.6475410 0.8012568 0.6865574 0.9415301 0.8552459 0.7222404 0.8656284 ##           y         z ## 1 0.8845355 0.9492350 ## 2 0.8683607 0.8152459 ## 3 0.8835519 0.8234973 ## 4 0.8295082 0.7040437 ## 5 0.9681421 0.8576503 ## 6 0.8666667 0.7646448"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dylan Carbone. Author, maintainer. Tom August. Author. Gary Powney. Author. Charlie Outhwaite. Author. Jack Hatfield. Author. Mark Logie. Author. Stephen Freeman. Author. Nick Isaac. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Carbone D, August T, Powney G, Outhwaite C, Hatfield J, Logie M, Freeman S, Isaac N (2024). BRCindicators: Creating multispecies biodiversity indicators. R package version 1.3.7, https://github.com/BiologicalRecordsCentre/BRCindicators.","code":"@Manual{,   title = {BRCindicators: Creating multispecies biodiversity indicators},   author = {Dylan Carbone and Tom August and Gary Powney and Charlie Outhwaite and Jack Hatfield and Mark Logie and Stephen Freeman and Nick Isaac},   year = {2024},   note = {R package version 1.3.7},   url = {https://github.com/BiologicalRecordsCentre/BRCindicators}, }"},{"path":"/index.html","id":"brcindicators","dir":"","previous_headings":"","what":"Creating multispecies biodiversity indicators","title":"Creating multispecies biodiversity indicators","text":"functions BRCindicators work yearly estimates species abundance occurrence aggregate scaled indicator value bootstrapped confidence intervals Installing package easy can done couple lines R info read vignette","code":"library(devtools) install_github(repo = 'biologicalrecordscentre/BRCindicators') vignette('BRCindicators')"},{"path":"/reference/bats.html","id":null,"dir":"Reference","previous_headings":"","what":"Data - National Bat Monitoring Programme, UK — bats","title":"Data - National Bat Monitoring Programme, UK — bats","text":"dataset National Bat Monitoring Programme, national (UK) abundance indices eight bat species 1998-2014. information see Barlow et al (2015). 136 lines data, seven NA, reflecting late entry time series two species (Natterer's Brown Long-eared bats).","code":""},{"path":"/reference/bats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data - National Bat Monitoring Programme, UK — bats","text":"","code":"data(bats)"},{"path":"/reference/bats.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data - National Bat Monitoring Programme, UK — bats","text":"four columns data: \"species\" species' name (abbreviation common name) \"year\" year index value refers (integer) \"collated_index\" national index abundance. time-series species fixed value 100 second year data. \"index\" national index abundance natural log scale.","code":""},{"path":"/reference/bats.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data - National Bat Monitoring Programme, UK — bats","text":"https://doi.org/10.1016/j.biocon.2014.11.022","code":""},{"path":"/reference/bats.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data - National Bat Monitoring Programme, UK — bats","text":"Barlow, K. E., Briggs, P. ., Haysom, K. ., Hutson, . M., Lechiara, N. L., Racey, P. ., … Langton, S. D. (2015). Citizen science reveals trends bat populations: National Bat Monitoring Programme Great Britain. Biological Conservation, 182, 14–26. https://doi.org/10.1016/j.biocon.2014.11.022","code":""},{"path":"/reference/bats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data - National Bat Monitoring Programme, UK — bats","text":"","code":"data(bats) head(bats) #>   species year collated_index    index #> 1 lshorse 1998           93.9 4.542230 #> 2 lshorse 1999          100.0 4.605170 #> 3 lshorse 2000          112.1 4.719391 #> 4 lshorse 2001          113.9 4.735321 #> 5 lshorse 2002          120.2 4.789157 #> 6 lshorse 2003          126.5 4.840242"},{"path":"/reference/bma.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian Meta-analysis — bma","title":"Bayesian Meta-analysis — bma","text":"Use Bayesian meta-analysis create indicator species index values, optionally incorporating standard error.","code":""},{"path":"/reference/bma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian Meta-analysis — bma","text":"","code":"bma(   data,   plot = TRUE,   model = \"smooth\",   parallel = FALSE,   n.cores = parallel::detectCores() - 1,   incl.model = TRUE,   n.iter = 10000,   n.thin = 5,   m.scale = \"loge\",   num.knots = 12,   seFromData = FALSE,   Y1perfect = TRUE,   rescale_indices = NULL,   rescaleYr = 1,   baseline = 100,   errorY1 = FALSE,   save.sppars = TRUE,   incl.2deriv = FALSE,   CI = 95,   seed = NULL )"},{"path":"/reference/bma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian Meta-analysis — bma","text":"data data.frame 3-4 columns: `species`, `year`, `index`, `se` (standard error). `se` column optional  NB: Index values assumed unbounded (logarithmic scale) plot Logical, trace plot plotted diagnose model output? model type model used. See details. parallel TRUE model chains run parallel using one fewer cores available computer default. NOTE: typically work parallel use cluster PCs. n.cores running code parallel option specifies number cores use. incl.model TRUE model added attribute object returned n.iter number iterations model run. Defaults 10,000 avoid long run times though much longer runs usually required reach convergence n.thin Thinning rate Markov chains. Defaults 5. m.scale measurement scale data. scale data assumed logarithmic. specify log scale data ('loge', 'log10', 'logit'). Defaults 'loge'. num.knots using either smooth models specifies number knots. seFromData Logical. standard errors read data (`TRUE`) estimated (`FALSE`)?  Defaults `FALSE` Y1perfect Logical. first year species' index assumed known without error (`TRUE`)? Defaults `TRUE` rescale_indices Integer. value standardising species time-series start common value (e.g. 0). Defaults NULL (.e. standardisation) rescaleYr Integer. year indicator use reference value (.e. baseline). Values greater number years dataset set final year. Defaults 1 (first year) baseline Integer. value indicator baseline year (defaults 100) errorY1 Logical. indicator presented (`TRUE`) without (`FALSE`) uncertainty baseline year. Defaults `FALSE`. save.sppars Logical. species-specific parameters monitored? Defaults TRUE incl.2deriv Logical. Option include estimation second derivatives indicator (`TRUE`)? Defaults `FALSE` CI defines credible intervals posterior distribution report. Defaults 95th percentile seed Option set custom seed initialize JAGS chains, reproducibility. integer. argument deprecated next version, can always set outside function .","code":""},{"path":"/reference/bma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian Meta-analysis — bma","text":"Returns dataframe 7 columns: Year, Index.Mprime, lowerCI.Mprime, upperCI.Mprime, Index.M, lowerCI.M , upperCI.M.  Columns headed `M` `Mprime` means M M' parameters  defined Freeman et al (2020). 'upper' 'lower' columns credible intervals, width defined `CI` argument. Note M M' alternate ways calculating multispecies indicator: means nearly always virtually identical, uncertainty M usually much wider M'. See Freeman et al (2020) details.","code":""},{"path":"/reference/bma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian Meta-analysis — bma","text":"number model choose : \"smooth\" default option. Indicator defined Growth rates, Ruppert smoother, allowing species join late. Error first year species' time-series assumed zero. indicator expected value geometric mean across species (missing species imputed).   Includes three options: `seFromData` `Y1perfect` `incl.2deriv`. See bayesian_meta_analysis mode details. Using default values `seFromData = FALSE` `Y1perfect = TRUE` options used Freeman  et al. (2020). \"smooth_det2\" Equivalent smooth `seFromData = TRUE` `Y1perfect = FALSE`. Retained backwards compatability. Choosing option overwrite user-entered options `seFromData` `Y1perfect`. \"smooth_det_sigtheta\" Equivalent smooth `seFromData = FALSE` `Y1perfect = FALSE`. Retained backwards compatability. Choosing option overwrite user-entered options `seFromData` `Y1perfect`.","code":""},{"path":"/reference/bma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian Meta-analysis — bma","text":"Freeman, S.N., Isaac, N.J.B., Besbeas, P.T., Dennis, E.B. & Morgan, B.J.T. (2020)              generic method estimating smoothing multispecies biodiversity indices, robust intermittent data.              Journal Agricultural Biological Environmental Statistics, revision.","code":""},{"path":"/reference/bma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian Meta-analysis — bma","text":"","code":"# Only run if there is a JAGS installation if(suppressWarnings(runjags::testjags(silent = TRUE)$JAGS.found)){  # Create some example data in the format required data <- data.frame(species = rep(letters, each = 50),                    year = rep(1:50, length(letters)),                    index = rnorm(n = 50 * length(letters), mean = 0, sd = 1),                    se = runif(n = 50 * length(letters), min = 0.01, max = .1))  # Run the Bayesian meta-analysis bma_indicator <- bma(data, model=\"smooth\", m.scale=\"logit\", n.iter=100)  # Plot the resulting indicator plot_indicator(indicator = bma_indicator[,'Index.Mprime'],                CIs = bma_indicator[,c(3,4)])        }"},{"path":"/reference/bootstrap_indicator.html","id":null,"dir":"Reference","previous_headings":"","what":"Bootstrapping indicator — bootstrap_indicator","title":"Bootstrapping indicator — bootstrap_indicator","text":"function takes dataframe multi-species data scaled adds confidence intervals indicator value.","code":""},{"path":"/reference/bootstrap_indicator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bootstrapping indicator — bootstrap_indicator","text":"","code":"bootstrap_indicator(   Data,   iterations = 10000,   CI_limits = c(0.025, 0.975),   verbose = TRUE )"},{"path":"/reference/bootstrap_indicator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bootstrapping indicator — bootstrap_indicator","text":"Data matrix named column give species' values year rows. iterations number bootstrap iterations use. CI_limits confidence limits return vector two numbers. default c(0.025, 0.975) 95 percent conficence intervals. verbose TRUE progress printed screen.","code":""},{"path":"/reference/bootstrap_indicator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bootstrapping indicator — bootstrap_indicator","text":"matrix. row year, species         scaled value. also additional column, 'geomean' giving         geometric mean year.","code":""},{"path":"/reference/butterflies_hs.html","id":null,"dir":"Reference","previous_headings":"","what":"Data - UK Butterfly Monitoring Scheme - Habitat Specialists — butterflies_hs","title":"Data - UK Butterfly Monitoring Scheme - Habitat Specialists — butterflies_hs","text":"dataset UK Butterfly Monitoring Scheme national abundance indices 26 species regarded habitat specialists 1976-2017. 1000 rows data. Ten species complete time-series (42 years data); 15 species join late (9 1970s, 3 1980s 3 1990s); Swallowtail (Papilio machaon) spans full range years data 1978.","code":""},{"path":"/reference/butterflies_hs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data - UK Butterfly Monitoring Scheme - Habitat Specialists — butterflies_hs","text":"","code":"data(butterflies_hs)"},{"path":"/reference/butterflies_hs.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data - UK Butterfly Monitoring Scheme - Habitat Specialists — butterflies_hs","text":"four columns data: \"species\" species' name (Latin binomial) \"year\" year index value refers (integer) \"index\" \"collated\" index abundance log10 scale. time-series species fixed mean exactly 2. Since 10^2 = 100, time-series centered value 100. \"se\" standard errors index value (log10 scale), estimated underlying statistical model.","code":""},{"path":"/reference/butterflies_hs.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data - UK Butterfly Monitoring Scheme - Habitat Specialists — butterflies_hs","text":"https://catalogue.ceh.ac.uk/documents/ace3c3ef-df89-40b9-ba8b-106997fd6d9c","code":""},{"path":"/reference/butterflies_hs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data - UK Butterfly Monitoring Scheme - Habitat Specialists — butterflies_hs","text":"Botham, M.S.; Brereton, T.; Harris, S.; Harrower, C.; Middlebrook, .; Randle, Z.; Roy, D.B. (2019). United Kingdom Butterfly Monitoring Scheme: collated indices 2017. NERC Environmental Information Data Centre. https://catalogue.ceh.ac.uk/documents/ace3c3ef-df89-40b9-ba8b-106997fd6d9c","code":""},{"path":"/reference/butterflies_hs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data - UK Butterfly Monitoring Scheme - Habitat Specialists — butterflies_hs","text":"","code":"data(butterflies_hs) head(butterflies_hs) #>         species year    index        se #> 85 Apatura iris 1979 1.551017 0.5004393 #> 86 Apatura iris 1980 2.165110 0.3656725 #> 87 Apatura iris 1981 1.551452 0.5004379 #> 88 Apatura iris 1982 1.918865 0.3949986 #> 89 Apatura iris 1983 2.324496 0.2890625 #> 90 Apatura iris 1984 2.126892 0.2997200"},{"path":"/reference/butterflies_wc.html","id":null,"dir":"Reference","previous_headings":"","what":"Data - UK Butterfly Monitoring Scheme - Wider Countryside Species — butterflies_wc","title":"Data - UK Butterfly Monitoring Scheme - Wider Countryside Species — butterflies_wc","text":"dataset UK Butterfly Monitoring Scheme national abundance indices 24 species regarded wider countryside species 1976-2017. 1005 lines data, reflecting late entry time series Scotch Argus (Erebia aethops). Time-series 23 species complete.","code":""},{"path":"/reference/butterflies_wc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data - UK Butterfly Monitoring Scheme - Wider Countryside Species — butterflies_wc","text":"","code":"data(butterflies_wc)"},{"path":"/reference/butterflies_wc.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data - UK Butterfly Monitoring Scheme - Wider Countryside Species — butterflies_wc","text":"four columns data: \"species\" species' name (Latin binomial) \"year\" year index value refers (integer) \"collated_index\" \"collated\" index abundance log10 scale. time-series species fixed mean exactly 2. Since 10^2 = 100, time-series centered value 100. \"se\" standard errors index value (log10 scale), estimated underlying statistical model.","code":""},{"path":"/reference/butterflies_wc.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data - UK Butterfly Monitoring Scheme - Wider Countryside Species — butterflies_wc","text":"https://catalogue.ceh.ac.uk/documents/ace3c3ef-df89-40b9-ba8b-106997fd6d9c","code":""},{"path":"/reference/butterflies_wc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data - UK Butterfly Monitoring Scheme - Wider Countryside Species — butterflies_wc","text":"Botham, M.S.; Brereton, T.; Harris, S.; Harrower, C.; Middlebrook, .; Randle, Z.; Roy, D.B. (2019). United Kingdom Butterfly Monitoring Scheme: collated indices 2017. NERC Environmental Information Data Centre. https://catalogue.ceh.ac.uk/documents/ace3c3ef-df89-40b9-ba8b-106997fd6d9c","code":""},{"path":"/reference/butterflies_wc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data - UK Butterfly Monitoring Scheme - Wider Countryside Species — butterflies_wc","text":"","code":"data(butterflies_wc) head(butterflies_wc) #>          species year    index         se #> 1 Aglais urticae 1976 2.105378 0.01652560 #> 2 Aglais urticae 1977 1.972035 0.01565523 #> 3 Aglais urticae 1978 2.277109 0.01259163 #> 4 Aglais urticae 1979 2.115708 0.01260353 #> 5 Aglais urticae 1980 2.135539 0.01243311 #> 6 Aglais urticae 1981 1.892195 0.01375867"},{"path":"/reference/CompositeTrend.html","id":null,"dir":"Reference","previous_headings":"","what":"CompositeTrend function — CompositeTrend","title":"CompositeTrend function — CompositeTrend","text":"function can used produce composite metrics change (indicators), whilst propagating uncertainty individual species trend estimates final composite trend metric. function takes dataframe sampled annual occupancy estimates across multiple species returns single composite trend metric uncertainty. approach suitable species without missing years.","code":""},{"path":"/reference/CompositeTrend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CompositeTrend function — CompositeTrend","text":"","code":"CompositeTrend(   indata,   output_path,   trend_choice = \"arithmetic_logit_occ\",   group_name,   save_iterations = \"yes\",   TrendScale = NULL,   plot_output = TRUE )"},{"path":"/reference/CompositeTrend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CompositeTrend function — CompositeTrend","text":"indata file path csv file containing dataframe contains year columns (prefixed \"X\", e.g \"X1985\"), species column (\"spp\"), iteration identifier (\"iter\"). year columns contain annual occupancy estimates species-year-iteration combination question. output_path location outputs saved. trend_choice approach used combine individual species estimates single composite trend. See details. group_name name species group running, used naming output files. save_iterations want save composite trend estimates individual iteration, generally used estimating temporal trends uncertainty. TrendScale Traditionally indicators scaled first year set given number, 100 case UK biodiversity indicators. value can chosen , scaling default. plot_output plot resulting composite indicator: TRUE FALSE. \"arithmetic_logit_occ\" - raw occupancy values  converted log odds scale (using logit function).  arithmetic mean across species used create composite trend  iteration. means converted back odds scale (exp) \"geometric_raw_occ\" - Take geometric mean across species  raw occupancy estimates \"arithmetic_raw_occ\" - potentially drop , used.","code":""},{"path":"/reference/CompositeTrend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CompositeTrend function — CompositeTrend","text":"summary file. .csv saved output_path location \t\t   contains annual composite indicator estimate (summarized across \t\t   iterations wither mean median). unique number \t\t   species contributing indicator shown \"spp_num\" column. \t\t   Various forms uncertainty (estimated across iterations) \t\t   annual composite trend presented, including upper lower \t\t   95","code":""},{"path":"/reference/dragonflies.html","id":null,"dir":"Reference","previous_headings":"","what":"Data - British Dragonfly Society, UK — dragonflies","title":"Data - British Dragonfly Society, UK — dragonflies","text":"dataset contains annual occupancy estimates 45 species dragonflies damselflies UK, 1970-2015. 2039 rows: 44 species estimate every year, Small red-eyed damselfly (Erythromma viridulum) estimates prior 2001 (first year recorded UK). models based biological records data British Dragonfly Society. data derived Bayesian occupancy detection models, described Outhwaite et al (2019).","code":""},{"path":"/reference/dragonflies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data - British Dragonfly Society, UK — dragonflies","text":"","code":"data(dragonflies)"},{"path":"/reference/dragonflies.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data - British Dragonfly Society, UK — dragonflies","text":"six columns data: \"species\" species' name (Latin binomial) \"year\" year index value refers (integer) \"occupancy\" national index occupancy, defined proportion occupied 1 km grid cells. \"index\" national index occupancy logit (log odds) scale. \"se\" Standard error posterior distribution logit occupancy \"inAtlas\" Logical. Identifies 38 species included 2014 Atlas Dragonflies Britain Ireland.","code":""},{"path":"/reference/dragonflies.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data - British Dragonfly Society, UK — dragonflies","text":"https://doi.org/10.1038/s41597-019-0269-1","code":""},{"path":"/reference/dragonflies.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data - British Dragonfly Society, UK — dragonflies","text":"Charlotte L. Outhwaite, Gary D. Powney, Tom . August, Richard E. Chandler, Stephanie Rorke, Oliver L. Pescott, Martin Harvey, Helen E. Roy, Richard Fox, David B. Roy, Keith Alexander, Stuart Ball, Tristan Bantock, Tony Barber, Björn C. Beckmann, Tony Cook, Jim Flanagan, Adrian Fowles, Peter Hammond, Peter Harvey, David Hepper, Dave Hubble, John Kramer, Paul Lee, Craig MacAdam, Roger Morris, Adrian Norris, Stephen Palmer, Colin W. Plant, Janet Simkin, Alan Stubbs, Peter Sutton, Mark Telfer, Ian Wallace & Nick J. B. Isaac. (2019). Annual estimates occupancy bryophytes, lichens invertebrates UK, 1970-2015. Scientific Data, 6(1), 259. https://doi.org/10.1038/s41597-019-0269-1","code":""},{"path":"/reference/dragonflies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data - British Dragonfly Society, UK — dragonflies","text":"","code":"data(dragonflies) head(dragonflies) #>           species year   occupancy     index        se inAtlas #> 1 Aeshna caerulea 1970 0.008910437 -4.976236 0.8054036    TRUE #> 2 Aeshna caerulea 1971 0.008632160 -4.978542 0.7563802    TRUE #> 3 Aeshna caerulea 1972 0.008522486 -4.962654 0.7082640    TRUE #> 4 Aeshna caerulea 1973 0.008486339 -4.938483 0.6507256    TRUE #> 5 Aeshna caerulea 1974 0.008469835 -4.909426 0.5812156    TRUE #> 6 Aeshna caerulea 1975 0.008496479 -4.872143 0.4971814    TRUE"},{"path":"/reference/GAM_smoothing.html","id":null,"dir":"Reference","previous_headings":"","what":"GAM smoothing — GAM_smoothing","title":"GAM smoothing — GAM_smoothing","text":"function uses GAM smooth numeric vector","code":""},{"path":"/reference/GAM_smoothing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GAM smoothing — GAM_smoothing","text":"","code":"GAM_smoothing(values, years = 1:length(values), plot = FALSE, ...)"},{"path":"/reference/GAM_smoothing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GAM smoothing — GAM_smoothing","text":"values numeric vector smoothed years Optional, years value corresponds numeric vector. plot TRUE plot generated showing smoothed spline. ... arguements passed mgcv::gam","code":""},{"path":"/reference/GAM_smoothing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GAM smoothing — GAM_smoothing","text":"smoothed/predicted values returned well  model object used making predictions.","code":""},{"path":"/reference/get_bmaBUGScode.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract BMA BUGS code — get_bmaBUGScode","title":"Extract BMA BUGS code — get_bmaBUGScode","text":"Gets copy BUGS code writes screen (optionally) text file","code":""},{"path":"/reference/get_bmaBUGScode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract BMA BUGS code — get_bmaBUGScode","text":"","code":"get_bmaBUGScode(   option = \"smooth\",   print.screen = FALSE,   save.local = FALSE,   incl.2deriv = FALSE,   Y1perfect = FALSE,   seFromData = FALSE )"},{"path":"/reference/get_bmaBUGScode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract BMA BUGS code — get_bmaBUGScode","text":"option text string defining particular variant desired print.screen Logical, code printed console? save.local Logical, text file BUGS code produced? incl.2deriv Logical, calculation indicator's second derivative? Y1perfect Logical, first year species assumed known without error (`TRUE`) seFromData Logical, standard errors read data (`TRUE`) estimated (`FALSE`)","code":""},{"path":"/reference/get_bmaBUGScode.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract BMA BUGS code — get_bmaBUGScode","text":"number model choose : \"smooth\" default option. Indicator defined Growth rates, Ruppert smoother, allowing species join late. Error first year species' time-series assumed zero. indicator expected value geometric mean across species (missing species imputed).   Includes three options: `seFromData` `Y1perfect` `incl.2deriv`. See bayesian_meta_analysis mode details. Using default values `seFromData = FALSE` `Y1perfect = TRUE` options used Freeman  et al. (2020). \"smooth_det2\" Equivalent smooth `seFromData = TRUE` `Y1perfect = FALSE`. Retained backwards compatability. Choosing option overwrite user-entered options `seFromData` `Y1perfect`. \"smooth_det_sigtheta\" Equivalent smooth `seFromData = FALSE` `Y1perfect = FALSE`. Retained backwards compatability. Choosing option overwrite user-entered options `seFromData` `Y1perfect`. \"smooth_det\" Specific variant smooth_det2 - deprecated retained backward compatibility","code":""},{"path":"/reference/get_bmaBUGScode.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract BMA BUGS code — get_bmaBUGScode","text":"","code":"get_bmaBUGScode(option=\"smooth\", print.screen=TRUE, save.local=FALSE) #> model { #>     ###################  Define priors  ########################### #>  #>   # process errors #>   tau.spi <- pow(sigma.spi,-2) #>   sigma.spi ~ dunif(0.0001,30) #>  #>   # observation error is constant #>   theta ~ dunif(0.0001,10) #>  #>     ######################### Smoothing ####################### #>  #>     beta[1] ~ dnorm(0, 0.000001) #>     beta[2] ~ dnorm(0, 0.000001) #>     taub ~ dgamma(0.000001, 0.000001) #>     for(k in 1:num.knots){b[k]~dnorm(0,taub)} #>    #>     for (t in 1:(nyears - 1)){ #>       logLambda[t] <- m[t] #>       m[t] <- mfe[t] + mre[t] #>       mfe[t] <- beta[1] * X[t,1] + beta[2] * X[t,2] #>       for (k in 1:num.knots){ #>         temp[t,k] <- b[k] * Z[t,k] #>       } #>       mre[t]<-sum(temp[t,1:num.knots]) #>     }   #>    #>     ###################  Define likelihood  ########################### #>  #>     M[1] <- 0  #>    #>     for (t in 2:nyears){ #>       M[t] <- M[t-1] + logLambda[t-1] #>     } #>  #>     for (s in 1:nsp){ #>       for (t in 1:(nyears-1)){ #>         spgrowth[s,t] ~ dnorm(logLambda[t], tau.spi) #>     }} #>  #>     for (s in 1:nsp){ #>       for (t in 1:FY[s]){ #>         spindex[s,t] <- spindex[s,t+1] - spgrowth[s,t] #>       } #>  #>       for (t in (FY[s]+1):(nyears)){ #>         spindex[s,t] <- estimate[s,FY[s]] + sum(spgrowth[s,FY[s]:(t-1)]) #>         estimate[s,t] ~ dnorm(spindex[s,t], tau.obs[s,t]) #>         tau.obs[s,t] <- pow(theta, -2) #>       }} #>  #>   ####################  geomean of expected values ###################### #>    #>   for (t in 1:nyears){ #>     Mprime[t] <- sum(spindex[,t])/nsp #>   } #>  #> } #> [1] \"model {\\n    ###################  Define priors  ###########################\\n\\n  # process errors\\n  tau.spi <- pow(sigma.spi,-2)\\n  sigma.spi ~ dunif(0.0001,30)\\n\\n  # observation error is constant\\n  theta ~ dunif(0.0001,10)\\n\\n    ######################### Smoothing #######################\\n\\n    beta[1] ~ dnorm(0, 0.000001)\\n    beta[2] ~ dnorm(0, 0.000001)\\n    taub ~ dgamma(0.000001, 0.000001)\\n    for(k in 1:num.knots){b[k]~dnorm(0,taub)}\\n  \\n    for (t in 1:(nyears - 1)){\\n      logLambda[t] <- m[t]\\n      m[t] <- mfe[t] + mre[t]\\n      mfe[t] <- beta[1] * X[t,1] + beta[2] * X[t,2]\\n      for (k in 1:num.knots){\\n        temp[t,k] <- b[k] * Z[t,k]\\n      }\\n      mre[t]<-sum(temp[t,1:num.knots])\\n    }  \\n  \\n    ###################  Define likelihood  ###########################\\n\\n    M[1] <- 0 \\n  \\n    for (t in 2:nyears){\\n      M[t] <- M[t-1] + logLambda[t-1]\\n    }\\n\\n    for (s in 1:nsp){\\n      for (t in 1:(nyears-1)){\\n        spgrowth[s,t] ~ dnorm(logLambda[t], tau.spi)\\n    }}\\n\\n    for (s in 1:nsp){\\n      for (t in 1:FY[s]){\\n        spindex[s,t] <- spindex[s,t+1] - spgrowth[s,t]\\n      }\\n\\n      for (t in (FY[s]+1):(nyears)){\\n        spindex[s,t] <- estimate[s,FY[s]] + sum(spgrowth[s,FY[s]:(t-1)])\\n        estimate[s,t] ~ dnorm(spindex[s,t], tau.obs[s,t])\\n        tau.obs[s,t] <- pow(theta, -2)\\n      }}\\n\\n  ####################  geomean of expected values ######################\\n  \\n  for (t in 1:nyears){\\n    Mprime[t] <- sum(spindex[,t])/nsp\\n  }\\n\\n}\" get_bmaBUGScode(option=\"smooth_JABES\", print.screen=TRUE, save.local=FALSE) #> model { #>     ###################  Define priors  ########################### #>  #>   # process errors #>   tau.spi <- pow(sigma.spi,-2) #>   sigma.spi ~ dunif(0.0001,30) #>  #>   # observation error is constant #>   theta ~ dunif(0.0001,10) #>  #>     ######################### Smoothing ####################### #>  #>     beta[1] ~ dnorm(0, 0.000001) #>     beta[2] ~ dnorm(0, 0.000001) #>     taub ~ dgamma(0.000001, 0.000001) #>     for(k in 1:num.knots){b[k]~dnorm(0,taub)} #>    #>     for (t in 1:(nyears - 1)){ #>       logLambda[t] <- m[t] #>       m[t] <- mfe[t] + mre[t] #>       mfe[t] <- beta[1] * X[t,1] + beta[2] * X[t,2] #>       for (k in 1:num.knots){ #>         temp[t,k] <- b[k] * Z[t,k] #>       } #>       mre[t]<-sum(temp[t,1:num.knots]) #>     }   #>    #>     ###################  Define likelihood  ########################### #>  #>     M[1] <- 0  #>    #>     for (t in 2:nyears){ #>       M[t] <- M[t-1] + logLambda[t-1] #>     } #>  #>     for (s in 1:nsp){ #>       for (t in 1:(nyears-1)){ #>         spgrowth[s,t] ~ dnorm(logLambda[t], tau.spi) #>     }} #>  #>     for (s in 1:nsp){ #>       for (t in 1:(FY[s]-1)){ #>         spindex[s,t] <- spindex[s,t+1] - spgrowth[s,t] #>     } #>  #>     spindex[s,FY[s]] <- estimate[s,FY[s]] # we assume the first year is known without error #>  #>     for (t in (FY[s]+1):(nyears)){ #>       spindex[s,t] <- estimate[s,FY[s]] + sum(spgrowth[s,FY[s]:(t-1)]) #>       estimate[s,t] ~ dnorm(spindex[s,t], tau.obs[s,t]) #>       tau.obs[s,t] <- pow(theta, -2) #>     }} #>  #>   ####################  geomean of expected values ###################### #>    #>   for (t in 1:nyears){ #>     Mprime[t] <- sum(spindex[,t])/nsp #>   } #>  #> } #> [1] \"model {\\n    ###################  Define priors  ###########################\\n\\n  # process errors\\n  tau.spi <- pow(sigma.spi,-2)\\n  sigma.spi ~ dunif(0.0001,30)\\n\\n  # observation error is constant\\n  theta ~ dunif(0.0001,10)\\n\\n    ######################### Smoothing #######################\\n\\n    beta[1] ~ dnorm(0, 0.000001)\\n    beta[2] ~ dnorm(0, 0.000001)\\n    taub ~ dgamma(0.000001, 0.000001)\\n    for(k in 1:num.knots){b[k]~dnorm(0,taub)}\\n  \\n    for (t in 1:(nyears - 1)){\\n      logLambda[t] <- m[t]\\n      m[t] <- mfe[t] + mre[t]\\n      mfe[t] <- beta[1] * X[t,1] + beta[2] * X[t,2]\\n      for (k in 1:num.knots){\\n        temp[t,k] <- b[k] * Z[t,k]\\n      }\\n      mre[t]<-sum(temp[t,1:num.knots])\\n    }  \\n  \\n    ###################  Define likelihood  ###########################\\n\\n    M[1] <- 0 \\n  \\n    for (t in 2:nyears){\\n      M[t] <- M[t-1] + logLambda[t-1]\\n    }\\n\\n    for (s in 1:nsp){\\n      for (t in 1:(nyears-1)){\\n        spgrowth[s,t] ~ dnorm(logLambda[t], tau.spi)\\n    }}\\n\\n    for (s in 1:nsp){\\n      for (t in 1:(FY[s]-1)){\\n        spindex[s,t] <- spindex[s,t+1] - spgrowth[s,t]\\n    }\\n\\n    spindex[s,FY[s]] <- estimate[s,FY[s]] # we assume the first year is known without error\\n\\n    for (t in (FY[s]+1):(nyears)){\\n      spindex[s,t] <- estimate[s,FY[s]] + sum(spgrowth[s,FY[s]:(t-1)])\\n      estimate[s,t] ~ dnorm(spindex[s,t], tau.obs[s,t])\\n      tau.obs[s,t] <- pow(theta, -2)\\n    }}\\n\\n  ####################  geomean of expected values ######################\\n  \\n  for (t in 1:nyears){\\n    Mprime[t] <- sum(spindex[,t])/nsp\\n  }\\n\\n}\" get_bmaBUGScode(option=\"smooth_det\", print.screen=TRUE, save.local=FALSE) #> model { #>  #>   ###################  Define priors #>   # process errors #>   tau.spi <- pow(sigma.spi,-2) #>   sigma.spi ~ dunif(0,30) #>   tau.sg <- pow(sigma.sg,-2) #>   sigma.sg ~ dunif(0,1000) #>  #>   # observation errors #>   # one value per site-species #>   for (s in 1:nsp){    #>     for (t in 1:nyears){ #>       sigma.obs[s,t] ~ dunif(0, max_se) # for the missing values #>     }} #>    #>   for (s in 1:nsp){ #>     spindex[s,1]~dnorm(Mprime.raw[1],tau.spi) #>   } #>    #>   ###################  Define likelihood  ####################### #>    #>   for (t in 1:(nyears-1)){ #>     logLambda[t] <- Mprime.raw[t+1] - Mprime.raw[t] #>   } #>    #>   for (s in 1:nsp){ #>     for (t in 1:(nyears-1)){ #>       spgrowth[s,t]~dnorm(logLambda[t],tau.sg) #>     } #>   } #>    #>   for (s in 1:nsp){ #>     for (t in 2:(nyears)){ #>       spindex[s,t]<-spindex[s,1] + sum(spgrowth[s,1:(t-1)]) #>     } #>   } #>    #>   for (s in 1:nsp){ #>     for (t in 1:(nyears)){ #>       estimate[s,t] ~ dnorm(spindex[s,t], tau.obs[s,t]) #>       tau.obs[s,t] <- pow(sigma.obs[s,t], -2) #>     } #>   } #>    #>   M <- m #>    #>   #########################  end likelihood ########################### #>    #>  #>     ######################### Smoothing ####################### #>  #>     beta[1] ~ dnorm(0, 0.000001) #>     beta[2] ~ dnorm(0, 0.000001) #>     taub ~ dgamma(0.000001, 0.000001) #>     for(k in 1:num.knots){b[k]~dnorm(0,taub)} #>    #>     for (t in 1:(nyears - 1)){ #>       logLambda[t] <- m[t] #>       m[t] <- mfe[t] + mre[t] #>       mfe[t] <- beta[1] * X[t,1] + beta[2] * X[t,2] #>       for (k in 1:num.knots){ #>         temp[t,k] <- b[k] * Z[t,k] #>       } #>       mre[t]<-sum(temp[t,1:num.knots]) #>     }   #>    #> } #> [1] \"model {\\n\\n  ###################  Define priors\\n  # process errors\\n  tau.spi <- pow(sigma.spi,-2)\\n  sigma.spi ~ dunif(0,30)\\n  tau.sg <- pow(sigma.sg,-2)\\n  sigma.sg ~ dunif(0,1000)\\n\\n  # observation errors\\n  # one value per site-species\\n  for (s in 1:nsp){   \\n    for (t in 1:nyears){\\n      sigma.obs[s,t] ~ dunif(0, max_se) # for the missing values\\n    }}\\n  \\n  for (s in 1:nsp){\\n    spindex[s,1]~dnorm(Mprime.raw[1],tau.spi)\\n  }\\n  \\n  ###################  Define likelihood  #######################\\n  \\n  for (t in 1:(nyears-1)){\\n    logLambda[t] <- Mprime.raw[t+1] - Mprime.raw[t]\\n  }\\n  \\n  for (s in 1:nsp){\\n    for (t in 1:(nyears-1)){\\n      spgrowth[s,t]~dnorm(logLambda[t],tau.sg)\\n    }\\n  }\\n  \\n  for (s in 1:nsp){\\n    for (t in 2:(nyears)){\\n      spindex[s,t]<-spindex[s,1] + sum(spgrowth[s,1:(t-1)])\\n    }\\n  }\\n  \\n  for (s in 1:nsp){\\n    for (t in 1:(nyears)){\\n      estimate[s,t] ~ dnorm(spindex[s,t], tau.obs[s,t])\\n      tau.obs[s,t] <- pow(sigma.obs[s,t], -2)\\n    }\\n  }\\n  \\n  M <- m\\n  \\n  #########################  end likelihood ###########################\\n  \\n\\n    ######################### Smoothing #######################\\n\\n    beta[1] ~ dnorm(0, 0.000001)\\n    beta[2] ~ dnorm(0, 0.000001)\\n    taub ~ dgamma(0.000001, 0.000001)\\n    for(k in 1:num.knots){b[k]~dnorm(0,taub)}\\n  \\n    for (t in 1:(nyears - 1)){\\n      logLambda[t] <- m[t]\\n      m[t] <- mfe[t] + mre[t]\\n      mfe[t] <- beta[1] * X[t,1] + beta[2] * X[t,2]\\n      for (k in 1:num.knots){\\n        temp[t,k] <- b[k] * Z[t,k]\\n      }\\n      mre[t]<-sum(temp[t,1:num.knots])\\n    }  \\n  \\n}\" get_bmaBUGScode(option=\"smooth_det2\", print.screen=TRUE, save.local=FALSE) #> model { #>     ###################  Define priors  ########################### #>  #>   # process errors #>   tau.spi <- pow(sigma.spi,-2) #>   sigma.spi ~ dunif(0.0001,30) #>  #>   # observation errors: one value per site-species #>   for (s in 1:nsp){ #>    for (t in 1:nyears){ #>     sigma.obs[s,t] ~ dunif(0.0001, max_se) # for the missing values #>   }} #>      #>  #>     ######################### Smoothing ####################### #>  #>     beta[1] ~ dnorm(0, 0.000001) #>     beta[2] ~ dnorm(0, 0.000001) #>     taub ~ dgamma(0.000001, 0.000001) #>     for(k in 1:num.knots){b[k]~dnorm(0,taub)} #>    #>     for (t in 1:(nyears - 1)){ #>       logLambda[t] <- m[t] #>       m[t] <- mfe[t] + mre[t] #>       mfe[t] <- beta[1] * X[t,1] + beta[2] * X[t,2] #>       for (k in 1:num.knots){ #>         temp[t,k] <- b[k] * Z[t,k] #>       } #>       mre[t]<-sum(temp[t,1:num.knots]) #>     }   #>    #>     ###################  Define likelihood  ########################### #>  #>     M[1] <- 0  #>    #>     for (t in 2:nyears){ #>       M[t] <- M[t-1] + logLambda[t-1] #>     } #>  #>     for (s in 1:nsp){ #>       for (t in 1:(nyears-1)){ #>         spgrowth[s,t] ~ dnorm(logLambda[t], tau.spi) #>     }} #>  #>     for (s in 1:nsp){ #>       for (t in 1:FY[s]){ #>         spindex[s,t] <- spindex[s,t+1] - spgrowth[s,t] #>       } #>  #>       for (t in (FY[s]+1):(nyears)){ #>         spindex[s,t] <- estimate[s,FY[s]] + sum(spgrowth[s,FY[s]:(t-1)]) #>         estimate[s,t] ~ dnorm(spindex[s,t], tau.obs[s,t]) #>         tau.obs[s,t] <- pow(sigma.obs[s,t], -2) #>       }} #>  #>   ####################  geomean of expected values ###################### #>    #>   for (t in 1:nyears){ #>     Mprime[t] <- sum(spindex[,t])/nsp #>   } #>  #> } #> [1] \"model {\\n    ###################  Define priors  ###########################\\n\\n  # process errors\\n  tau.spi <- pow(sigma.spi,-2)\\n  sigma.spi ~ dunif(0.0001,30)\\n\\n  # observation errors: one value per site-species\\n  for (s in 1:nsp){\\n   for (t in 1:nyears){\\n    sigma.obs[s,t] ~ dunif(0.0001, max_se) # for the missing values\\n  }}\\n    \\n\\n    ######################### Smoothing #######################\\n\\n    beta[1] ~ dnorm(0, 0.000001)\\n    beta[2] ~ dnorm(0, 0.000001)\\n    taub ~ dgamma(0.000001, 0.000001)\\n    for(k in 1:num.knots){b[k]~dnorm(0,taub)}\\n  \\n    for (t in 1:(nyears - 1)){\\n      logLambda[t] <- m[t]\\n      m[t] <- mfe[t] + mre[t]\\n      mfe[t] <- beta[1] * X[t,1] + beta[2] * X[t,2]\\n      for (k in 1:num.knots){\\n        temp[t,k] <- b[k] * Z[t,k]\\n      }\\n      mre[t]<-sum(temp[t,1:num.knots])\\n    }  \\n  \\n    ###################  Define likelihood  ###########################\\n\\n    M[1] <- 0 \\n  \\n    for (t in 2:nyears){\\n      M[t] <- M[t-1] + logLambda[t-1]\\n    }\\n\\n    for (s in 1:nsp){\\n      for (t in 1:(nyears-1)){\\n        spgrowth[s,t] ~ dnorm(logLambda[t], tau.spi)\\n    }}\\n\\n    for (s in 1:nsp){\\n      for (t in 1:FY[s]){\\n        spindex[s,t] <- spindex[s,t+1] - spgrowth[s,t]\\n      }\\n\\n      for (t in (FY[s]+1):(nyears)){\\n        spindex[s,t] <- estimate[s,FY[s]] + sum(spgrowth[s,FY[s]:(t-1)])\\n        estimate[s,t] ~ dnorm(spindex[s,t], tau.obs[s,t])\\n        tau.obs[s,t] <- pow(sigma.obs[s,t], -2)\\n      }}\\n\\n  ####################  geomean of expected values ######################\\n  \\n  for (t in 1:nyears){\\n    Mprime[t] <- sum(spindex[,t])/nsp\\n  }\\n\\n}\" get_bmaBUGScode(option=\"smooth_det_sigtheta\", print.screen=TRUE, save.local=FALSE) #> model { #>     ###################  Define priors  ########################### #>  #>   # process errors #>   tau.spi <- pow(sigma.spi,-2) #>   sigma.spi ~ dunif(0.0001,30) #>  #>   # observation error is constant #>   theta ~ dunif(0.0001,10) #>  #>     ######################### Smoothing ####################### #>  #>     beta[1] ~ dnorm(0, 0.000001) #>     beta[2] ~ dnorm(0, 0.000001) #>     taub ~ dgamma(0.000001, 0.000001) #>     for(k in 1:num.knots){b[k]~dnorm(0,taub)} #>    #>     for (t in 1:(nyears - 1)){ #>       logLambda[t] <- m[t] #>       m[t] <- mfe[t] + mre[t] #>       mfe[t] <- beta[1] * X[t,1] + beta[2] * X[t,2] #>       for (k in 1:num.knots){ #>         temp[t,k] <- b[k] * Z[t,k] #>       } #>       mre[t]<-sum(temp[t,1:num.knots]) #>     }   #>    #>     ###################  Define likelihood  ########################### #>  #>     M[1] <- 0  #>    #>     for (t in 2:nyears){ #>       M[t] <- M[t-1] + logLambda[t-1] #>     } #>  #>     for (s in 1:nsp){ #>       for (t in 1:(nyears-1)){ #>         spgrowth[s,t] ~ dnorm(logLambda[t], tau.spi) #>     }} #>  #>     for (s in 1:nsp){ #>       for (t in 1:FY[s]){ #>         spindex[s,t] <- spindex[s,t+1] - spgrowth[s,t] #>       } #>  #>       for (t in (FY[s]+1):(nyears)){ #>         spindex[s,t] <- estimate[s,FY[s]] + sum(spgrowth[s,FY[s]:(t-1)]) #>         estimate[s,t] ~ dnorm(spindex[s,t], tau.obs[s,t]) #>         tau.obs[s,t] <- pow(theta, -2) #>       }} #>  #>   ####################  geomean of expected values ###################### #>    #>   for (t in 1:nyears){ #>     Mprime[t] <- sum(spindex[,t])/nsp #>   } #>  #> } #> [1] \"model {\\n    ###################  Define priors  ###########################\\n\\n  # process errors\\n  tau.spi <- pow(sigma.spi,-2)\\n  sigma.spi ~ dunif(0.0001,30)\\n\\n  # observation error is constant\\n  theta ~ dunif(0.0001,10)\\n\\n    ######################### Smoothing #######################\\n\\n    beta[1] ~ dnorm(0, 0.000001)\\n    beta[2] ~ dnorm(0, 0.000001)\\n    taub ~ dgamma(0.000001, 0.000001)\\n    for(k in 1:num.knots){b[k]~dnorm(0,taub)}\\n  \\n    for (t in 1:(nyears - 1)){\\n      logLambda[t] <- m[t]\\n      m[t] <- mfe[t] + mre[t]\\n      mfe[t] <- beta[1] * X[t,1] + beta[2] * X[t,2]\\n      for (k in 1:num.knots){\\n        temp[t,k] <- b[k] * Z[t,k]\\n      }\\n      mre[t]<-sum(temp[t,1:num.knots])\\n    }  \\n  \\n    ###################  Define likelihood  ###########################\\n\\n    M[1] <- 0 \\n  \\n    for (t in 2:nyears){\\n      M[t] <- M[t-1] + logLambda[t-1]\\n    }\\n\\n    for (s in 1:nsp){\\n      for (t in 1:(nyears-1)){\\n        spgrowth[s,t] ~ dnorm(logLambda[t], tau.spi)\\n    }}\\n\\n    for (s in 1:nsp){\\n      for (t in 1:FY[s]){\\n        spindex[s,t] <- spindex[s,t+1] - spgrowth[s,t]\\n      }\\n\\n      for (t in (FY[s]+1):(nyears)){\\n        spindex[s,t] <- estimate[s,FY[s]] + sum(spgrowth[s,FY[s]:(t-1)])\\n        estimate[s,t] ~ dnorm(spindex[s,t], tau.obs[s,t])\\n        tau.obs[s,t] <- pow(theta, -2)\\n      }}\\n\\n  ####################  geomean of expected values ######################\\n  \\n  for (t in 1:nyears){\\n    Mprime[t] <- sum(spindex[,t])/nsp\\n  }\\n\\n}\""},{"path":"/reference/lambda_indicator.html","id":null,"dir":"Reference","previous_headings":"","what":"Rescale species values for indicator using Lambda interpolation — lambda_indicator","title":"Rescale species values for indicator using Lambda interpolation — lambda_indicator","text":"function takes output sparta occupancy model three dimensional array. first year set index value species average change across years species used calculate indicator. species contributes dataset years standard deviation across iterations meets sd threshold. Missing years middle species dataset filled using interpolation.","code":""},{"path":"/reference/lambda_indicator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rescale species values for indicator using Lambda interpolation — lambda_indicator","text":"","code":"lambda_indicator(   input,   index = 100,   threshold_sd = 0.2,   threshold_Rhat = 1.1,   threshold_yrs = 20,   upperQuantile = 0.975,   lowerQuantile = 0.025,   sample_size = NULL,   year_range = NULL,   region = NULL )"},{"path":"/reference/lambda_indicator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rescale species values for indicator using Lambda interpolation — lambda_indicator","text":"input Either string giving path occupancy model output files produced sparta, three dimensional array [species, year, iteration]. index index value first year, defaults 100. threshold_sd threshold standard deviation species-year value included. standard deviation value removed. threshold_Rhat threshold Rhat value species-year value included. Rhat value removed. rule used input path sparta output. threshold_yrs Numeric, minimum number years species must fulfill threshold_sd included. upperQuantile upper confidence interval use (probability) lowerQuantile lower confidence interval use (probability) sample_size numeric, NULL subsample iterations  used, equal number given. useful datasets large memory starts become limiting. year_range numeric vector length 2 giving start end year  data analysed. region Specify region aggregate data indicator  produced (example: ENGLAND, WALES, SCOTLAND). region name match name used running occDetFunc. NULL (default) function run  full data (psi.fs).","code":""},{"path":"/reference/lambda_indicator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rescale species values for indicator using Lambda interpolation — lambda_indicator","text":"list five elements: summary (data.frame), LogLambda values (three dimensional array, species - year - iterations), calculated removing species fail thresholds including interpolation, raw indicator value (value iteration year), average annual percentage change species (fist year ignored change 0), table giving 'good' years species defined thresholds. Please note number species contributing first year 0  fixed index value.","code":""},{"path":"/reference/lambda_indicator.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rescale species values for indicator using Lambda interpolation — lambda_indicator","text":"","code":"### Running from an array #### # number of species nsp = 50  # number of years nyr = 40  #number of iterations iter = 500  # Build a random set of data myArray <- array(data = rnorm(n = nsp*nyr*iter,                               mean = 0.5,                               sd = 0.1),                  dim = c(nsp, nyr, iter),                  dimnames = list(paste0('SP',1:nsp),                                  1:nyr,                                  1:iter))  # Ensure values are bounded by 0 and 1 myArray[myArray > 1] <- 1 myArray[myArray < 0] <- 0  # Run the lambda_indicator method on this data                 myIndicator <- lambda_indicator(myArray)  # Plot the indicator plot_indicator(myIndicator$summary[,'indicator'],                myIndicator$summary[,c('lower' ,'upper')])   ### Running from a directory of sparta ouput # myIndicator <- lambda_indicator('myfilepath/myfolder')"},{"path":"/reference/msi.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi-Species Indicator — msi","title":"Multi-Species Indicator — msi","text":"simple wrapper msi_tool make easier use R. Multi-Species Indicators (MSI) biodiversity indicators combine population development species single indicator. MSI-tool calculates MSI, confidence intervals MSIs linear flexible (smoothed) trends. trends classified terms like \"moderate increase\", \"strong decrease\" \"stable\". number additional analyses can performed like testing changepoints, comparison trends changepoint calculation testing total change time series.","code":""},{"path":"/reference/msi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi-Species Indicator — msi","text":"","code":"msi(data, jobname = \"MSI_job\", ...)"},{"path":"/reference/msi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi-Species Indicator — msi","text":"data data.frame 4 columns order: 'species', 'year', 'index', 'se' (standard error). index value base year (need first year), set 100, se 0. jobname Generic name output files ... parameters pass msi_tool","code":""},{"path":"/reference/msi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multi-Species Indicator — msi","text":"Returns dataframe 4 columns: Year, Index, lower2.5, upper97.5. last two columns credible intervals","code":""},{"path":"/reference/msi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multi-Species Indicator — msi","text":"","code":"# Create some example data in the format required nyr = 20 species = rep(letters, each = nyr) year = rev(rep(1:nyr, length(letters)))  # Create an index value that increases with time index = rep(seq(50, 100, length.out = nyr), length(letters)) # Add randomness to species index = index * runif(n = length(index), 0.7, 1.3) # Add correlated randomness acrosss species, to years index = index * rep(runif(0.8, 1.2, n = nyr), length(letters))  se = runif(n = nyr * length(letters), min = 10, max = 20)  data <- data.frame(species, year, index, se)  # Our species are decreasing plot(data$year, data$index)   # Species index values need to be 100 in the base year. Here I use # the first year as my base year and rescale to 100. The standard error # in the base year should be 0. min_year <- min(data$year)  for(sp in unique(data$species)){      subset_data <- data[data$species == sp, ]   multi_factor <- 100 / subset_data$index[subset_data$year == min_year]   data$index[data$species == sp] <- data$index[data$species == sp] * multi_factor   data$se[data$species == sp] <- data$se[data$species == sp] * multi_factor   data$se[data$species == sp][1] <- 0    }  # Run the MSI function msi_out <- msi(data, plot = FALSE)  # Plot the resulting indicator plot(msi_out)"},{"path":"/reference/msi_tool.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi-Species Indicator tool — msi_tool","title":"Multi-Species Indicator tool — msi_tool","text":"functionalised version code developed Statistics Netherlands (see source). See `msi`  wrapper removes need write files folder first. Multi-Species Indicators (MSI) biodiversity indicators combine population development species single indicator. MSI-tool calculates MSI, confidence intervals MSIs linear flexible (smoothed) trends. trends classified terms like \"moderate increase\", \"strong decrease\" \"stable\". number additional analyses can performed like testing changepoints, comparison trends changepoint calculation testing total change time series.","code":""},{"path":"/reference/msi_tool.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi-Species Indicator tool — msi_tool","text":"","code":"msi_tool(   wd = getwd(),   inputFile,   jobname = \"MSI_job\",   nsim = 1000,   SEbaseyear = NULL,   plotbaseyear = NULL,   index_smooth = \"SMOOTH\",   span = 0.75,   lastyears = 10,   maxCV = 3,   changepoint = NULL,   truncfac = 10,   TRUNC = 1,   plot = TRUE )"},{"path":"/reference/msi_tool.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Multi-Species Indicator tool — msi_tool","text":"https://www.cbs.nl/en-gb/society/nature--environment/indices--trends--trim--/msi-tool","code":""},{"path":"/reference/msi_tool.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi-Species Indicator tool — msi_tool","text":"wd path input ouput files inputFile name input file. must columns species, year, index, se order. index value base year (need first year), set 100 se 0. jobname Generic name output files nsim Number Monte Carlo simulations SEbaseyear Desired year set MSI 100 SE 0; usually first year time series plotbaseyear desired year set 100 plots index_smooth character, either 'INDEX' 'SMOOTH'. \"INDEX\" cause index plotbaseyear set 100; \"SMOOTH\" set smoothed trend value plotbaseyear 100. span Span proportion points use weighted estimation smoothed line. Values close 1 smoothed values close 0 lastyears last X years time series separate trend (short-term trends) calculated maxCV maximum allowed mean Coefficient Variation (CV) species indices (0.5 = 50 Species higher mean CV excluded. changepoint compare trends year truncfac truncation factor (=max year--year index ratio). Default Living Planet Index = 10. TRUNC set indices TRUNC value SE 0. TRUNC = 0 means truncation. plot logical, plots created","code":""},{"path":"/reference/plot.MSI.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to plots msi results — plot.MSI","title":"A function to plots msi results — plot.MSI","text":"Plots summary MSI analysis","code":""},{"path":"/reference/plot.MSI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to plots msi results — plot.MSI","text":"","code":"# S3 method for MSI plot(x, title = \"MSI results\", ...)"},{"path":"/reference/plot.MSI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to plots msi results — plot.MSI","text":"x object class MSI title Character, title plot ... currently ignored","code":""},{"path":"/reference/plot_indicator.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot indicator — plot_indicator","title":"Plot indicator — plot_indicator","text":"function plots indicator using ggplot2.","code":""},{"path":"/reference/plot_indicator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot indicator — plot_indicator","text":"","code":"plot_indicator(   indicator,   CIs,   year = 1:length(indicator),   index = indicator[1],   smoothed_line = NULL,   main = \"\" )"},{"path":"/reference/plot_indicator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot indicator — plot_indicator","text":"indicator numeric vector, one value year CIs matrix two columns, first column lower bound second upper bound. year numeric vector long indicator giving years index Numeric, index value, default taken  first value indicator smoothed_line numeric vector giving smoothed values plot see GAM_smoothing main Title given plot","code":""},{"path":"/reference/plot_indicator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot indicator — plot_indicator","text":"plot object returned","code":""},{"path":"/reference/plot_trend_stack.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot species trend stack plots — plot_trend_stack","title":"Plot species trend stack plots — plot_trend_stack","text":"function used reporting species trends generated indicators. takes vector categories plots stacked column plot","code":""},{"path":"/reference/plot_trend_stack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot species trend stack plots — plot_trend_stack","text":"","code":"plot_trend_stack(species_change)"},{"path":"/reference/plot_trend_stack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot species trend stack plots — plot_trend_stack","text":"species_change factor vector change categories. following levels \"strong increase\", \"increase\", \"change\", \"decrease\", \"strong decrease\".","code":""},{"path":"/reference/plot_trend_stack.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot species trend stack plots — plot_trend_stack","text":"Returns data.frame data plot. plot sent device.","code":""},{"path":"/reference/plot_trend_stack.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot species trend stack plots — plot_trend_stack","text":"","code":"### Running from an array #### set.seed(123)  # number of species nsp = 50  # number of years nyr = 40  #number of iterations iter = 500  # Build a random set of data myArray <- array(data = rnorm(n = nsp*nyr*iter,                               mean = 0.5,                               sd = 0.1),                  dim = c(nsp, nyr, iter),                  dimnames = list(paste0('SP',1:nsp),                                  1:nyr,                                  1:iter))  # Ensure values are bounded by 0 and 1 myArray[myArray > 1] <- 1 myArray[myArray < 0] <- 0  # Run the lambda_indicator method on this data                 myIndicator <- lambda_indicator(myArray)  # Plot the trend stack plot_trend_stack(myIndicator$species_change[,'category'])  #>    species_change Freq prop_spp #> 1 strong decrease    0        0 #> 2        decrease    0        0 #> 3       no change   50        1 #> 4        increase    0        0 #> 5 strong increase    0        0"},{"path":"/reference/rescale_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Rescale species values for indicator — rescale_posterior","title":"Rescale species values for indicator — rescale_posterior","text":"function takes output sparta occupancy model rescales posteriers gemean species first year. function accounts species data beginning period, bringing geomean, data end period, applying multiplier result species data.","code":""},{"path":"/reference/rescale_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rescale species values for indicator — rescale_posterior","text":"","code":"rescale_posterior(   input_dir,   subset_table = NULL,   index = 100,   max = 10000,   min = 1,   year_limit = 10,   upperQuantile = 0.975,   lowerQuantile = 0.025,   verbose = TRUE )"},{"path":"/reference/rescale_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rescale species values for indicator — rescale_posterior","text":"input_dir location occupancy model output files subset_table dataframe columns years rows species.  Column names must character years row names must match file names input_dir index index value first year, defaults 100. max upper limit allowed scaled values. Values greater  set equal max. min upper limit allowed scaled values. Values greater  set equal min. year_limit minimum length 'good years' species included upperQuantile upper confidence interval use (probability) lowerQuantile lower confidence interval use (probability) verbose TRUE progress written console","code":""},{"path":"/reference/rescale_posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rescale species values for indicator — rescale_posterior","text":"list two elements, summary (data.frame) rescaled data (list)","code":""},{"path":"/reference/rescale_posterior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Rescale species values for indicator — rescale_posterior","text":"two options calculating confidence intervals; first use 95 calculate indicator line iteration (given posterior data) present 97.5 2.5 quantiles lines. returned summary table.","code":""},{"path":"/reference/rescale_species.html","id":null,"dir":"Reference","previous_headings":"","what":"Rescale species values for indicator — rescale_species","title":"Rescale species values for indicator — rescale_species","text":"function takes dataframe multi-species data rescales value starting year . function accounts species data beginning period data teh end period.","code":""},{"path":"/reference/rescale_species.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rescale species values for indicator — rescale_species","text":"","code":"rescale_species(Data, index = 100, max = 10000, min = 1)"},{"path":"/reference/rescale_species.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rescale species values for indicator — rescale_species","text":"Data matrix, first column, named year, gives year. Subsequent named columns give species. Values table yearly values rescaled. index index value first year, defaults 100. max upper limit allowed scaled values. Values greater  set equal max. min upper limit allowed scaled values. Values greater  set equal min.","code":""},{"path":"/reference/rescale_species.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rescale species values for indicator — rescale_species","text":"matrix. row year, species         scaled value. also additional column, 'geomean' giving         geometric mean year.","code":""},{"path":"/reference/rescale_species.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rescale species values for indicator — rescale_species","text":"","code":"# We will create fake data which will mimic a summarised output from a sparta package occupancy detection model. Please see the vignette for more details.  # Create a matrix with random data using set.seed for reproducibility set.seed(123) data <- matrix(rnorm(50 * 27), nrow = 50, ncol = 27)  # Assign column names col_names <- c(\"year\", letters[1:26]) dimnames(data) <- list(NULL, col_names)  # Create the 'trends_summary' object trends_summary <- data  # Re-scale the data so that the value for all species in the first year is the same (all defaults used). # This function accounts for species that have no data at the beginning of the dataset by entering them at the geometric mean for that year, this stops them dramatically changing the indicator value in the year they join the dataset. # It also accounts for species that leave the dataset before the end by holding them at their last value. # Finally it limits the species values that can be given, preventing extremely high or low values biasing the indicator. rescale_species(Data = trends_summary) #>              year         a          b          c          d         e #>  [1,] -0.56047565 100.00000 100.000000 100.000000 100.000000 100.00000 #>  [2,] -0.23017749   1.00000   1.000000  97.626548  59.687411 149.59320 #>  [3,]  1.55870831   1.00000  34.725450  42.171664   1.000000  91.56406 #>  [4,]  0.07050839 540.26935  48.921648   1.000000  24.703998   1.00000 #>  [5,]  0.12928774   1.00000 133.954079   1.000000   1.000000   1.00000 #>  [6,]  1.71506499 598.64184   6.338304   1.000000   1.000000  23.57946 #>  [7,]  0.46091621   1.00000 110.486658  71.469058   1.000000   1.00000 #>  [8,] -1.26506123 230.78209 234.786955   1.000000   1.000000   1.00000 #>  [9,] -0.68685285  48.89269  53.522383 124.022497  75.081849  30.25533 #> [10,] -0.44566197  85.24508   1.000000   1.000000   1.000000 408.11775 #> [11,]  1.22408180 149.86646  80.988407 133.637115   5.423171 138.74157 #> [12,]  0.35981383   1.00000   1.000000   1.000000  11.082694 130.42245 #> [13,]  0.40077145   1.00000 227.740394   1.000000  56.051941   1.00000 #> [14,]  0.11068272   1.00000   7.821150 411.435839   1.000000   1.00000 #> [15,] -0.55584113   1.00000   1.000000   1.000000   1.000000   1.00000 #> [16,]  1.78691314 119.82095   1.000000  37.858688  76.209253   1.00000 #> [17,]  0.49785048 176.93526   1.000000  80.809735   1.000000  35.44993 #> [18,] -1.96661716  20.92395  90.188639   1.000000   1.000000 467.65548 #> [19,]  0.70135590 364.07425 119.608178  65.613375   1.000000 103.50822 #> [20,] -0.47279141 809.29130 144.160941  46.838432   1.000000   1.00000 #> [21,] -1.06782371   1.00000   1.000000   1.000000   1.000000   1.00000 #> [22,] -0.21797491   1.00000 133.370757   8.288665  28.105462   1.00000 #> [23,] -1.02600445 397.02527  69.053056   1.000000  50.474937   1.00000 #> [24,] -0.72889123   1.00000  36.048680 270.197656  32.180509 371.47595 #> [25,] -0.62503927   1.00000   1.000000   1.000000   1.000000   1.00000 #> [26,] -1.68669331 404.85449  91.771379   1.000000   2.717376 118.89079 #> [27,]  0.83778704   1.00000   1.000000   4.797072   1.000000   1.00000 #> [28,]  0.15337312   1.00000   1.000000  39.414173   1.000000   1.00000 #> [29,] -1.13813694  71.57135 135.395235  55.414746  40.233142   1.00000 #> [30,]  1.25381492   1.00000  10.037645   1.000000   1.000000   1.00000 #> [31,]  0.42646422   2.27547   1.000000   1.000000  88.925085 443.94631 #> [32,] -0.29507148 152.09327   1.000000 160.355831   1.000000   1.00000 #> [33,]  0.89512566   1.00000   1.000000   1.000000   9.757041   1.00000 #> [34,]  0.87813349 254.37404  59.472541   1.000000   1.000000  70.72673 #> [35,]  0.82158108   1.00000 289.024247   1.000000   1.000000   1.00000 #> [36,]  0.68864025 130.97423   1.000000   1.000000   1.000000   1.00000 #> [37,]  0.55391765 432.98810 205.606218 140.899524   1.000000   1.00000 #> [38,] -0.06191171 171.79222   1.000000  10.757028  19.054959   1.00000 #> [39,] -0.30596266   1.00000   1.000000  95.723829  14.749082  58.31968 #> [40,] -0.38047100 453.50322 203.248849   1.000000   1.000000   1.00000 #> [41,] -0.69470698 392.19552   1.000000  27.222894   1.000000   1.00000 #> [42,] -0.20791728 216.48515  36.908089   1.000000   1.000000   1.00000 #> [43,] -1.26539635  94.24172 221.302032  12.006965  68.039550   1.00000 #> [44,]  2.16895597   1.00000 213.211382   1.000000   1.000000 153.74430 #> [45,]  1.20796200 537.13107 225.439383   1.000000   1.000000   1.00000 #> [46,] -1.12310858   1.00000  74.732773 253.537501  86.517776   1.00000 #> [47,] -0.40288484 863.47143 205.763243  76.257357   1.000000   1.00000 #> [48,] -0.46665535 605.01327   1.000000   1.000000   1.000000 359.66250 #> [49,]  0.77996512   1.00000   1.000000   1.000000   1.000000   1.00000 #> [50,] -0.08336907   1.00000 181.168157   1.000000  22.078302   1.00000 #>                f          g          h          i         j          k #>  [1,] 100.000000 100.000000  100.00000 100.000000 100.00000 100.000000 #>  [2,] 105.235539   1.000000 1588.79102  73.170241 165.09560   1.000000 #>  [3,] 131.219707   1.000000  862.94537  30.431225   1.00000 131.460036 #>  [4,] 147.154810  11.492001   39.21032  49.998409   1.00000  29.568406 #>  [5,]  61.120491   1.000000    1.00000  64.120065 250.73675 195.515102 #>  [6,]   1.000000  32.898684 2243.93131   1.000000  15.80804   1.000000 #>  [7,] 281.612373  40.537237  475.49370  77.619916 148.85504   1.000000 #>  [8,]   1.000000   1.000000    1.00000   1.000000 344.03982   1.000000 #>  [9,]   1.000000   1.000000  732.51539  16.122515   1.00000   1.000000 #> [10,]   1.000000 253.359815    1.00000   1.000000  13.16043   1.000000 #> [11,]   1.000000   1.000000    1.00000  60.959419  16.17718   1.000000 #> [12,]   1.000000  64.160566    1.00000   1.000000   1.00000  68.495617 #> [13,] 241.418981  26.973578    1.00000  36.248806   1.00000   1.000000 #> [14,]  84.098326 100.958680  166.82341   1.000000   1.00000 175.644867 #> [15,]  49.220594  80.562091  562.39655   1.000000 102.41621   1.000000 #> [16,]   1.000000   1.000000 3593.38227  84.592319 122.08141  11.963385 #> [17,]  14.774203  37.259995  126.35406  51.796616  21.89805  63.082804 #> [18,] 175.975166   1.000000    1.00000 120.543863   1.00000  69.444004 #> [19,]   1.000000  84.430639    1.00000   4.554937 172.73512   1.000000 #> [20,]   1.000000   1.000000  754.90539  78.649392  30.62154   9.409586 #> [21,]   1.000000 238.119081    1.00000 138.102336   1.00000 113.771964 #> [22,]   1.000000   1.000000    1.00000   1.000000  17.98993   1.000000 #> [23,] 187.177758   1.000000    1.00000   1.000000 116.03738   1.000000 #> [24,]   1.000000  81.322766    1.00000   1.000000  45.84623  37.921731 #> [25,]  73.109834  50.262178  976.76061   1.000000   1.00000   1.000000 #> [26,]   1.000000   1.000000  612.23898  10.604045   1.00000 162.149026 #> [27,]   8.503687   1.000000    1.00000 119.707926   1.00000  79.684044 #> [28,]   1.000000  14.234857    1.00000   1.000000   1.00000   8.541412 #> [29,]   1.000000   1.000000    1.00000  26.076905   1.00000   1.000000 #> [30,]   1.000000   1.000000 1955.66136   1.000000  92.78344   3.089134 #> [31,]   1.000000   3.404237  259.00913   1.429717   1.00000   1.000000 #> [32,] 166.158269  18.742952    1.00000  21.955897  84.12354   1.000000 #> [33,] 100.889524  17.215387    1.00000  92.856021 236.01635   1.000000 #> [34,]   1.000000   1.000000 1367.17059   8.481416   1.00000  59.019475 #> [35,]   1.000000  46.912309    1.00000  49.835092   1.00000   1.000000 #> [36,] 286.926982 135.827323 1464.76205  54.450416   1.00000   1.000000 #> [37,] 190.709871  44.951916    1.00000  63.952165   1.00000  45.144267 #> [38,]  28.071752   1.000000    1.00000   1.000000   1.00000   1.000000 #> [39,]   1.000000   1.000000 3024.88868 113.735917 101.10723  69.000885 #> [40,]  14.244581  34.100788    1.00000   1.000000  33.60081   1.000000 #> [41,]   1.000000   1.000000 1687.20998   1.000000  45.39813   1.000000 #> [42,]   1.000000   1.000000    1.00000  98.157716  77.87097  55.032034 #> [43,]   1.000000  87.123185    1.00000  90.469924   1.00000  99.483443 #> [44,]   1.000000   1.000000  271.75183   1.000000 198.93300   1.000000 #> [45,]   7.267735   1.000000  877.03762   1.000000   1.00000  59.666673 #> [46,] 245.124993 148.175844    1.00000   1.000000   1.00000   1.000000 #> [47,]   1.000000   1.000000    1.00000  12.713010 199.14215   1.000000 #> [48,]  79.951947  83.327970    1.00000  11.524091   1.00000   1.000000 #> [49,] 136.178989   1.000000 2790.16865  25.455403   1.00000 139.800564 #> [50,]  25.153191   1.000000 2224.67078  38.601567  92.57719 220.132741 #>               l          m          n         o         p         q          r #>  [1,] 100.00000 100.000000 100.000000 100.00000 100.00000 100.00000 100.000000 #>  [2,]   1.00000   1.000000 211.535564   1.00000   1.00000   1.00000  78.030058 #>  [3,]   1.00000   1.000000  95.176658  33.24628 240.03429 180.77792   1.000000 #>  [4,]   1.00000  74.842445   1.000000  13.90755 323.60093   1.00000   1.000000 #>  [5,]  73.59184   1.000000 187.403686   1.00000  77.54349 412.76810   1.000000 #>  [6,]   1.00000  42.722325   1.000000   1.00000  40.44665   1.00000  61.587491 #>  [7,]   1.00000   1.000000   1.000000  65.83557   1.00000   1.00000   1.000000 #>  [8,]   1.00000   1.000000 124.167989   1.00000 606.65644   1.00000   4.789239 #>  [9,]   1.00000   1.000000   1.000000   1.00000  77.55500  26.09230   1.000000 #> [10,]   1.00000   1.000000   1.000000   1.00000   1.00000 288.76321   1.000000 #> [11,]   1.00000   1.000000   1.000000  35.08710   1.00000 162.05986   1.000000 #> [12,]   1.00000   1.000000  29.228604  40.07044   1.00000  25.33642 116.879227 #> [13,] 157.12944   1.000000  12.858327  40.07772   1.00000   1.00000   1.000000 #> [14,]   1.00000   1.464792  11.907698   1.00000  57.90168   1.00000 175.520404 #> [15,] 100.08685 116.019894   1.000000  23.96872  77.71131   1.00000   1.000000 #> [16,]   1.00000   1.000000   1.000000  62.91213 230.57681 454.05911   1.000000 #> [17,]   1.00000   1.000000   1.000000  82.97930   1.00000   1.00000   1.000000 #> [18,]   1.00000   8.013669  39.458014   1.00000 340.90530 201.15958 189.835159 #> [19,]   1.00000   1.000000   1.000000   1.00000   1.00000   1.00000   1.000000 #> [20,] 144.00293   1.000000   1.000000  96.71143   1.00000 296.29871   1.000000 #> [21,]   1.00000  26.720721 143.043938   1.00000   1.00000   1.00000  40.825370 #> [22,]  29.64494  15.171247 237.333035   1.00000 208.34458  25.54358  20.919788 #> [23,]  78.81067   1.000000   1.000000  29.73564   1.00000   1.00000   3.602871 #> [24,]  16.59108  28.383926 210.006921   1.00000 221.68253 160.69161   1.000000 #> [25,]   1.00000   1.000000   1.000000  18.17618   1.00000 263.89217   1.000000 #> [26,]  87.63083 101.196948   1.000000 122.06365   1.00000 346.93834   1.000000 #> [27,]  15.88325  57.771318   1.000000   1.00000   1.00000 141.85434   9.415862 #> [28,]   1.00000  68.493797   1.000000   1.00000   1.00000 327.82737   1.000000 #> [29,]   1.00000  44.035163 100.636442  30.86989   1.00000 221.67816   1.000000 #> [30,] 194.29177  35.764913   1.000000   1.00000   1.00000   1.00000   1.000000 #> [31,]   1.00000   1.000000   1.000000  52.87210 295.92241  84.84171   1.000000 #> [32,]   1.00000   1.000000   1.000000  58.78950   1.00000   1.00000 132.356214 #> [33,]  49.65114  37.522918 266.904682   1.00000 221.58203   1.00000   1.000000 #> [34,]  28.88517  51.423088   1.000000   1.00000 425.64173 217.15003  21.824579 #> [35,]   1.00000  53.736721   7.697676   1.00000   1.00000  96.26811   1.089210 #> [36,]   1.00000  21.387037   1.000000   1.00000  79.67785  81.34161  56.740913 #> [37,]   1.00000  12.330590   1.000000  51.83079   1.00000   1.00000  67.725673 #> [38,] 106.08783   1.000000  13.277058   1.00000   1.00000   1.00000  71.074210 #> [39,]  59.22875  16.575912  10.335241   1.00000  15.77813   1.00000  21.151910 #> [40,]   1.00000 107.221265   1.000000   1.00000  83.94636  70.30390   1.000000 #> [41,]   1.00000   4.716743   1.000000  25.63619   1.00000   1.00000   1.000000 #> [42,]  25.23870   1.000000   1.000000   1.00000 753.57410  99.95981  35.496508 #> [43,]  14.65098   1.000000   1.000000  57.63986   1.00000   1.00000 166.245232 #> [44,]  58.63171  40.699577   1.000000  21.66949  18.03159 325.20659  83.282874 #> [45,]   1.00000  79.843837   1.000000   1.00000 182.38065  81.91679  45.138954 #> [46,]  83.73778   1.000000 303.567028  53.22491   1.00000   1.00000   1.000000 #> [47,]   1.00000   8.378723   1.000000  25.24425   1.00000  42.87034  65.338528 #> [48,]   1.00000   5.027135  66.281812   1.00000 293.39167   1.00000   1.000000 #> [49,]  68.97636   1.000000   1.000000  15.02278 453.44396  66.00916  26.847819 #> [50,]  92.17508  83.262086   1.000000  42.08923   1.00000  43.31262 119.704911 #>                s          t         u          v          w         x #>  [1,]  100.00000 100.000000 100.00000 100.000000  100.00000 100.00000 #>  [2,]  711.71250 104.434261   1.00000  87.404945 1681.30668   1.00000 #>  [3,]    1.00000   1.805610 141.95652   1.000000    1.00000 137.37591 #>  [4,]    1.00000  13.273278   1.00000   1.000000    1.00000   1.00000 #>  [5,]    1.00000 256.009845 349.36340  17.497700    1.00000 101.67617 #>  [6,] 1148.12267   1.000000 176.41659   1.000000    1.00000 176.92369 #>  [7,]    1.00000   1.000000   1.00000   1.000000  581.96007   1.00000 #>  [8,]    1.00000   1.000000  16.45974   9.162817    1.00000 178.75210 #>  [9,] 1006.01074   1.000000 216.13074   1.000000 2081.06116   1.00000 #> [10,]    1.00000  44.884503 168.27794  17.601283 1467.23929  47.48784 #> [11,]    1.00000   1.000000 447.12740   1.000000    1.00000  32.56231 #> [12,]    1.00000   1.000000   1.00000 104.494822  584.72491   1.00000 #> [13,]    1.00000 122.385356 336.75944 264.684516  115.78081  43.25286 #> [14,]    1.00000   1.000000 312.74606   1.000000  202.24790   1.00000 #> [15,]    1.00000  21.213817   1.00000 115.466522 1141.84048   1.00000 #> [16,]    1.00000   1.000000   1.00000  90.082629 3543.39081 133.22429 #> [17,] 1308.54437   1.000000   1.00000   1.000000    1.00000   1.00000 #> [18,] 1183.00033 126.722442 138.12295   1.000000    1.00000   1.00000 #> [19,]   54.89027   1.000000   1.00000 171.978315 2262.07506   1.00000 #> [20,]  411.34090   1.000000 536.78878   1.000000    1.00000   1.00000 #> [21,]    1.00000  16.478230 161.46120   1.000000    1.00000  67.69105 #> [22,] 1494.53639  16.361410   1.00000   1.000000    1.00000   1.00000 #> [23,] 1060.93700   1.000000   1.00000 152.328115 1680.11498   1.00000 #> [24,]  779.74638   1.000000   1.00000   1.000000    1.00000   1.00000 #> [25,]    1.00000 165.544982 103.45589   1.000000  175.55384   1.00000 #> [26,]  777.62731   1.000000   1.00000 347.606122    1.00000 138.22463 #> [27,]  565.98047   1.000000 155.15291   1.000000 1010.80248   1.00000 #> [28,]    1.00000   1.000000   1.00000   1.000000   17.72438 187.35002 #> [29,]  228.47398   1.000000   1.00000  32.736665 3122.06860  64.26759 #> [30,]    1.00000   1.000000   1.00000   1.000000 1364.95376  58.45803 #> [31,]    1.00000 120.198508 574.78753  53.526953    1.00000   1.00000 #> [32,]  796.11332   1.000000 100.35824   1.000000 1239.80143 315.18394 #> [33,]  216.24369  95.847576  69.58651  51.149474   76.47723   1.00000 #> [34,]  365.81695  45.995045   1.00000   1.000000  821.34736   1.00000 #> [35,]    1.00000   1.000000 199.07164   1.000000    1.00000   1.00000 #> [36,]  544.72275 114.168966   1.00000   1.000000    1.00000   1.00000 #> [37,]   58.10979   1.000000   1.00000   1.000000 1443.73127   1.00000 #> [38,]    1.00000   1.000000 277.08083 141.818912  538.93923   1.00000 #> [39,]  749.38225   1.000000   1.00000 172.397298    1.00000 109.99913 #> [40,]    1.00000   1.000000   1.00000   1.000000 3859.75540 162.86135 #> [41,]    1.00000 102.666061 534.01340   1.000000  561.40915   1.00000 #> [42,]  760.43696   1.000000   1.00000   1.000000    1.00000 130.04901 #> [43,]    1.00000   8.930577 172.82803   7.558633    1.00000 229.78510 #> [44,]  151.00134  26.193270 306.92326  10.579157    1.00000   1.00000 #> [45,]    1.00000   1.000000   1.00000  31.663417 1515.88706   1.00000 #> [46,]   63.69395 102.470566 134.04977   1.000000    1.00000 104.98964 #> [47,]    1.00000 131.899237 132.49391   1.000000 1145.81057  29.53101 #> [48,]  956.45163  49.656709 313.97560 130.686468    1.00000  88.53350 #> [49,]  369.96333   1.000000 146.06190   1.000000 1415.61365 226.61678 #> [50,]  176.40350   1.000000   1.00000  33.083878    1.00000  62.44786 #>                y         z  indicator #>  [1,] 100.000000 100.00000 100.000000 #>  [2,]  59.228365  42.89649  18.434784 #>  [3,]  41.230376 153.09207  14.593365 #>  [4,]  36.710466   1.00000   7.030356 #>  [5,] 122.784230   1.00000  13.449395 #>  [6,]   1.000000   1.00000   8.085288 #>  [7,]   1.000000 162.70082   6.706895 #>  [8,]  56.284614   1.00000   5.384031 #>  [9,]   1.000000 125.92040  10.927643 #> [10,]   7.036714   1.00000   6.618135 #> [11,]  70.483644   1.00000   6.922303 #> [12,]  71.626332  67.16126   6.900736 #> [13,]   1.000000   1.00000   9.254198 #> [14,]   1.000000  99.99237   8.342027 #> [15,]   6.998053  63.82710   8.984141 #> [16,] 101.076020   1.00000  15.079417 #> [17,]  40.507747  90.58142   8.378396 #> [18,] 136.256136 227.14503  19.490218 #> [19,]   1.000000   1.00000   6.211307 #> [20,] 107.033018   1.00000  11.895386 #> [21,]  83.959422  77.84705   6.330338 #> [22,]  58.199365 265.97442   8.679146 #> [23,]  39.431416   1.00000   8.705079 #> [24,]   1.000000   1.00000   9.699392 #> [25,]   1.000000   1.00000   4.393866 #> [26,]  21.811849   1.00000  15.012011 #> [27,]   4.648553   1.00000   6.033059 #> [28,]  89.685588  93.60815   3.937974 #> [29,]   1.000000  46.84329  11.003278 #> [30,]   1.000000 230.36703   4.861715 #> [31,]   1.000000  98.24635   7.490526 #> [32,]   1.000000   1.00000   9.594441 #> [33,]   1.000000  38.77631  11.887064 #> [34,]   1.000000  28.57198  14.172596 #> [35,]   1.000000  15.01343   3.437549 #> [36,]   1.000000 248.57982   9.733159 #> [37,]   1.000000   1.00000   8.415488 #> [38,]   1.000000 192.53611   6.202011 #> [39,]   1.000000  27.81953  13.540560 #> [40,]   1.000000  58.49652   7.363468 #> [41,]  62.137014  29.15650   6.858212 #> [42,] 168.606683   1.00000   8.816510 #> [43,]   1.000000  77.63637  10.537778 #> [44,] 141.978039 104.45120  15.475271 #> [45,]   7.894082 202.69464  10.250864 #> [46,]  10.985259 107.46570  11.875874 #> [47,]  30.885701 155.54817  12.770525 #> [48,]   1.000000   1.00000  10.406502 #> [49,]   1.000000 115.10932  14.701704 #> [50,]  86.378872   1.00000  15.526217  # Now, I have 'messed up' the data a bit by including two species with data missing at the beginning and one species with data missing at the end. We also have one species with some very high values. trends_summary[1:3, 'a'] <- NA trends_summary[1:5, 'b'] <- NA trends_summary[2:4, 'c'] <- 1000 trends_summary[45:50, 'd'] <- NA  # Let's run this data again through our scaling function (all defaults used) rescale_species(Data = trends_summary) #>              year         a          b            c          d         e #>  [1,] -0.56047565        NA         NA   100.000000 100.000000 100.00000 #>  [2,] -0.23017749        NA         NA 10000.000000  59.687411 149.59320 #>  [3,]  1.55870831        NA         NA 10000.000000   1.000000  91.56406 #>  [4,]  0.07050839  7.942748         NA 10000.000000  24.703998   1.00000 #>  [5,]  0.12928774  1.000000         NA     1.000000   1.000000   1.00000 #>  [6,]  1.71506499  8.800908   6.896343     1.000000   1.000000  23.57946 #>  [7,]  0.46091621  1.000000 120.214163    71.469058   1.000000   1.00000 #>  [8,] -1.26506123  3.392833 255.458150     1.000000   1.000000   1.00000 #>  [9,] -0.68685285  1.000000  58.234619   124.022497  75.081849  30.25533 #> [10,] -0.44566197  1.253227   1.000000     1.000000   1.000000 408.11775 #> [11,]  1.22408180  2.203256  88.118817   133.637115   5.423171 138.74157 #> [12,]  0.35981383  1.000000   1.000000     1.000000  11.082694 130.42245 #> [13,]  0.40077145  1.000000 247.791193     1.000000  56.051941   1.00000 #> [14,]  0.11068272  1.000000   8.509743   411.435839   1.000000   1.00000 #> [15,] -0.55584113  1.000000   1.000000     1.000000   1.000000   1.00000 #> [16,]  1.78691314  1.761543   1.000000    37.858688  76.209253   1.00000 #> [17,]  0.49785048  2.601207   1.000000    80.809735   1.000000  35.44993 #> [18,] -1.96661716  1.000000  98.129058     1.000000   1.000000 467.65548 #> [19,]  0.70135590  5.352423 130.138763    65.613375   1.000000 103.50822 #> [20,] -0.47279141 11.897763 156.853209    46.838432   1.000000   1.00000 #> [21,] -1.06782371  1.000000   1.000000     1.000000   1.000000   1.00000 #> [22,] -0.21797491  1.000000 145.113032     8.288665  28.105462   1.00000 #> [23,] -1.02600445  5.836851  75.132649     1.000000  50.474937   1.00000 #> [24,] -0.72889123  1.000000  39.222491   270.197656  32.180509 371.47595 #> [25,] -0.62503927  1.000000   1.000000     1.000000   1.000000   1.00000 #> [26,] -1.68669331  5.951952  99.851147     1.000000   2.717376 118.89079 #> [27,]  0.83778704  1.000000   1.000000     4.797072   1.000000   1.00000 #> [28,]  0.15337312  1.000000   1.000000    39.414173   1.000000   1.00000 #> [29,] -1.13813694  1.052203 147.315749    55.414746  40.233142   1.00000 #> [30,]  1.25381492  1.000000  10.921382     1.000000   1.000000   1.00000 #> [31,]  0.42646422  1.000000   1.000000     1.000000  88.925085 443.94631 #> [32,] -0.29507148  2.235993   1.000000   160.355831   1.000000   1.00000 #> [33,]  0.89512566  1.000000   1.000000     1.000000   9.757041   1.00000 #> [34,]  0.87813349  3.739670  64.708643     1.000000   1.000000  70.72673 #> [35,]  0.82158108  1.000000 314.470621     1.000000   1.000000   1.00000 #> [36,]  0.68864025  1.925512   1.000000     1.000000   1.000000   1.00000 #> [37,]  0.55391765  6.365557 223.708273   140.899524   1.000000   1.00000 #> [38,] -0.06191171  2.525596   1.000000    10.757028  19.054959   1.00000 #> [39,] -0.30596266  1.000000   1.000000    95.723829  14.749082  58.31968 #> [40,] -0.38047100  6.667159 221.143355     1.000000   1.000000   1.00000 #> [41,] -0.69470698  5.765846   1.000000    27.222894   1.000000   1.00000 #> [42,] -0.20791728  3.182648  40.157564     1.000000   1.000000   1.00000 #> [43,] -1.26539635  1.385491 240.785983    12.006965  68.039550   1.00000 #> [44,]  2.16895597  1.000000 231.983013     1.000000   1.000000 153.74430 #> [45,]  1.20796200  7.896610 245.287596     1.000000   1.000000   1.00000 #> [46,] -1.12310858  1.000000  81.312422   253.537501   1.000000   1.00000 #> [47,] -0.40288484 12.694290 223.879122    76.257357   1.000000   1.00000 #> [48,] -0.46665535  8.894578   1.000000     1.000000   1.000000 359.66250 #> [49,]  0.77996512  1.000000   1.000000     1.000000   1.000000   1.00000 #> [50,] -0.08336907  1.000000 197.118627     1.000000   1.000000   1.00000 #>                f          g          h          i         j          k #>  [1,] 100.000000 100.000000  100.00000 100.000000 100.00000 100.000000 #>  [2,] 105.235539   1.000000 1588.79102  73.170241 165.09560   1.000000 #>  [3,] 131.219707   1.000000  862.94537  30.431225   1.00000 131.460036 #>  [4,] 147.154810  11.492001   39.21032  49.998409   1.00000  29.568406 #>  [5,]  61.120491   1.000000    1.00000  64.120065 250.73675 195.515102 #>  [6,]   1.000000  32.898684 2243.93131   1.000000  15.80804   1.000000 #>  [7,] 281.612373  40.537237  475.49370  77.619916 148.85504   1.000000 #>  [8,]   1.000000   1.000000    1.00000   1.000000 344.03982   1.000000 #>  [9,]   1.000000   1.000000  732.51539  16.122515   1.00000   1.000000 #> [10,]   1.000000 253.359815    1.00000   1.000000  13.16043   1.000000 #> [11,]   1.000000   1.000000    1.00000  60.959419  16.17718   1.000000 #> [12,]   1.000000  64.160566    1.00000   1.000000   1.00000  68.495617 #> [13,] 241.418981  26.973578    1.00000  36.248806   1.00000   1.000000 #> [14,]  84.098326 100.958680  166.82341   1.000000   1.00000 175.644867 #> [15,]  49.220594  80.562091  562.39655   1.000000 102.41621   1.000000 #> [16,]   1.000000   1.000000 3593.38227  84.592319 122.08141  11.963385 #> [17,]  14.774203  37.259995  126.35406  51.796616  21.89805  63.082804 #> [18,] 175.975166   1.000000    1.00000 120.543863   1.00000  69.444004 #> [19,]   1.000000  84.430639    1.00000   4.554937 172.73512   1.000000 #> [20,]   1.000000   1.000000  754.90539  78.649392  30.62154   9.409586 #> [21,]   1.000000 238.119081    1.00000 138.102336   1.00000 113.771964 #> [22,]   1.000000   1.000000    1.00000   1.000000  17.98993   1.000000 #> [23,] 187.177758   1.000000    1.00000   1.000000 116.03738   1.000000 #> [24,]   1.000000  81.322766    1.00000   1.000000  45.84623  37.921731 #> [25,]  73.109834  50.262178  976.76061   1.000000   1.00000   1.000000 #> [26,]   1.000000   1.000000  612.23898  10.604045   1.00000 162.149026 #> [27,]   8.503687   1.000000    1.00000 119.707926   1.00000  79.684044 #> [28,]   1.000000  14.234857    1.00000   1.000000   1.00000   8.541412 #> [29,]   1.000000   1.000000    1.00000  26.076905   1.00000   1.000000 #> [30,]   1.000000   1.000000 1955.66136   1.000000  92.78344   3.089134 #> [31,]   1.000000   3.404237  259.00913   1.429717   1.00000   1.000000 #> [32,] 166.158269  18.742952    1.00000  21.955897  84.12354   1.000000 #> [33,] 100.889524  17.215387    1.00000  92.856021 236.01635   1.000000 #> [34,]   1.000000   1.000000 1367.17059   8.481416   1.00000  59.019475 #> [35,]   1.000000  46.912309    1.00000  49.835092   1.00000   1.000000 #> [36,] 286.926982 135.827323 1464.76205  54.450416   1.00000   1.000000 #> [37,] 190.709871  44.951916    1.00000  63.952165   1.00000  45.144267 #> [38,]  28.071752   1.000000    1.00000   1.000000   1.00000   1.000000 #> [39,]   1.000000   1.000000 3024.88868 113.735917 101.10723  69.000885 #> [40,]  14.244581  34.100788    1.00000   1.000000  33.60081   1.000000 #> [41,]   1.000000   1.000000 1687.20998   1.000000  45.39813   1.000000 #> [42,]   1.000000   1.000000    1.00000  98.157716  77.87097  55.032034 #> [43,]   1.000000  87.123185    1.00000  90.469924   1.00000  99.483443 #> [44,]   1.000000   1.000000  271.75183   1.000000 198.93300   1.000000 #> [45,]   7.267735   1.000000  877.03762   1.000000   1.00000  59.666673 #> [46,] 245.124993 148.175844    1.00000   1.000000   1.00000   1.000000 #> [47,]   1.000000   1.000000    1.00000  12.713010 199.14215   1.000000 #> [48,]  79.951947  83.327970    1.00000  11.524091   1.00000   1.000000 #> [49,] 136.178989   1.000000 2790.16865  25.455403   1.00000 139.800564 #> [50,]  25.153191   1.000000 2224.67078  38.601567  92.57719 220.132741 #>               l          m          n         o         p         q          r #>  [1,] 100.00000 100.000000 100.000000 100.00000 100.00000 100.00000 100.000000 #>  [2,]   1.00000   1.000000 211.535564   1.00000   1.00000   1.00000  78.030058 #>  [3,]   1.00000   1.000000  95.176658  33.24628 240.03429 180.77792   1.000000 #>  [4,]   1.00000  74.842445   1.000000  13.90755 323.60093   1.00000   1.000000 #>  [5,]  73.59184   1.000000 187.403686   1.00000  77.54349 412.76810   1.000000 #>  [6,]   1.00000  42.722325   1.000000   1.00000  40.44665   1.00000  61.587491 #>  [7,]   1.00000   1.000000   1.000000  65.83557   1.00000   1.00000   1.000000 #>  [8,]   1.00000   1.000000 124.167989   1.00000 606.65644   1.00000   4.789239 #>  [9,]   1.00000   1.000000   1.000000   1.00000  77.55500  26.09230   1.000000 #> [10,]   1.00000   1.000000   1.000000   1.00000   1.00000 288.76321   1.000000 #> [11,]   1.00000   1.000000   1.000000  35.08710   1.00000 162.05986   1.000000 #> [12,]   1.00000   1.000000  29.228604  40.07044   1.00000  25.33642 116.879227 #> [13,] 157.12944   1.000000  12.858327  40.07772   1.00000   1.00000   1.000000 #> [14,]   1.00000   1.464792  11.907698   1.00000  57.90168   1.00000 175.520404 #> [15,] 100.08685 116.019894   1.000000  23.96872  77.71131   1.00000   1.000000 #> [16,]   1.00000   1.000000   1.000000  62.91213 230.57681 454.05911   1.000000 #> [17,]   1.00000   1.000000   1.000000  82.97930   1.00000   1.00000   1.000000 #> [18,]   1.00000   8.013669  39.458014   1.00000 340.90530 201.15958 189.835159 #> [19,]   1.00000   1.000000   1.000000   1.00000   1.00000   1.00000   1.000000 #> [20,] 144.00293   1.000000   1.000000  96.71143   1.00000 296.29871   1.000000 #> [21,]   1.00000  26.720721 143.043938   1.00000   1.00000   1.00000  40.825370 #> [22,]  29.64494  15.171247 237.333035   1.00000 208.34458  25.54358  20.919788 #> [23,]  78.81067   1.000000   1.000000  29.73564   1.00000   1.00000   3.602871 #> [24,]  16.59108  28.383926 210.006921   1.00000 221.68253 160.69161   1.000000 #> [25,]   1.00000   1.000000   1.000000  18.17618   1.00000 263.89217   1.000000 #> [26,]  87.63083 101.196948   1.000000 122.06365   1.00000 346.93834   1.000000 #> [27,]  15.88325  57.771318   1.000000   1.00000   1.00000 141.85434   9.415862 #> [28,]   1.00000  68.493797   1.000000   1.00000   1.00000 327.82737   1.000000 #> [29,]   1.00000  44.035163 100.636442  30.86989   1.00000 221.67816   1.000000 #> [30,] 194.29177  35.764913   1.000000   1.00000   1.00000   1.00000   1.000000 #> [31,]   1.00000   1.000000   1.000000  52.87210 295.92241  84.84171   1.000000 #> [32,]   1.00000   1.000000   1.000000  58.78950   1.00000   1.00000 132.356214 #> [33,]  49.65114  37.522918 266.904682   1.00000 221.58203   1.00000   1.000000 #> [34,]  28.88517  51.423088   1.000000   1.00000 425.64173 217.15003  21.824579 #> [35,]   1.00000  53.736721   7.697676   1.00000   1.00000  96.26811   1.089210 #> [36,]   1.00000  21.387037   1.000000   1.00000  79.67785  81.34161  56.740913 #> [37,]   1.00000  12.330590   1.000000  51.83079   1.00000   1.00000  67.725673 #> [38,] 106.08783   1.000000  13.277058   1.00000   1.00000   1.00000  71.074210 #> [39,]  59.22875  16.575912  10.335241   1.00000  15.77813   1.00000  21.151910 #> [40,]   1.00000 107.221265   1.000000   1.00000  83.94636  70.30390   1.000000 #> [41,]   1.00000   4.716743   1.000000  25.63619   1.00000   1.00000   1.000000 #> [42,]  25.23870   1.000000   1.000000   1.00000 753.57410  99.95981  35.496508 #> [43,]  14.65098   1.000000   1.000000  57.63986   1.00000   1.00000 166.245232 #> [44,]  58.63171  40.699577   1.000000  21.66949  18.03159 325.20659  83.282874 #> [45,]   1.00000  79.843837   1.000000   1.00000 182.38065  81.91679  45.138954 #> [46,]  83.73778   1.000000 303.567028  53.22491   1.00000   1.00000   1.000000 #> [47,]   1.00000   8.378723   1.000000  25.24425   1.00000  42.87034  65.338528 #> [48,]   1.00000   5.027135  66.281812   1.00000 293.39167   1.00000   1.000000 #> [49,]  68.97636   1.000000   1.000000  15.02278 453.44396  66.00916  26.847819 #> [50,]  92.17508  83.262086   1.000000  42.08923   1.00000  43.31262 119.704911 #>                s          t         u          v          w         x #>  [1,]  100.00000 100.000000 100.00000 100.000000  100.00000 100.00000 #>  [2,]  711.71250 104.434261   1.00000  87.404945 1681.30668   1.00000 #>  [3,]    1.00000   1.805610 141.95652   1.000000    1.00000 137.37591 #>  [4,]    1.00000  13.273278   1.00000   1.000000    1.00000   1.00000 #>  [5,]    1.00000 256.009845 349.36340  17.497700    1.00000 101.67617 #>  [6,] 1148.12267   1.000000 176.41659   1.000000    1.00000 176.92369 #>  [7,]    1.00000   1.000000   1.00000   1.000000  581.96007   1.00000 #>  [8,]    1.00000   1.000000  16.45974   9.162817    1.00000 178.75210 #>  [9,] 1006.01074   1.000000 216.13074   1.000000 2081.06116   1.00000 #> [10,]    1.00000  44.884503 168.27794  17.601283 1467.23929  47.48784 #> [11,]    1.00000   1.000000 447.12740   1.000000    1.00000  32.56231 #> [12,]    1.00000   1.000000   1.00000 104.494822  584.72491   1.00000 #> [13,]    1.00000 122.385356 336.75944 264.684516  115.78081  43.25286 #> [14,]    1.00000   1.000000 312.74606   1.000000  202.24790   1.00000 #> [15,]    1.00000  21.213817   1.00000 115.466522 1141.84048   1.00000 #> [16,]    1.00000   1.000000   1.00000  90.082629 3543.39081 133.22429 #> [17,] 1308.54437   1.000000   1.00000   1.000000    1.00000   1.00000 #> [18,] 1183.00033 126.722442 138.12295   1.000000    1.00000   1.00000 #> [19,]   54.89027   1.000000   1.00000 171.978315 2262.07506   1.00000 #> [20,]  411.34090   1.000000 536.78878   1.000000    1.00000   1.00000 #> [21,]    1.00000  16.478230 161.46120   1.000000    1.00000  67.69105 #> [22,] 1494.53639  16.361410   1.00000   1.000000    1.00000   1.00000 #> [23,] 1060.93700   1.000000   1.00000 152.328115 1680.11498   1.00000 #> [24,]  779.74638   1.000000   1.00000   1.000000    1.00000   1.00000 #> [25,]    1.00000 165.544982 103.45589   1.000000  175.55384   1.00000 #> [26,]  777.62731   1.000000   1.00000 347.606122    1.00000 138.22463 #> [27,]  565.98047   1.000000 155.15291   1.000000 1010.80248   1.00000 #> [28,]    1.00000   1.000000   1.00000   1.000000   17.72438 187.35002 #> [29,]  228.47398   1.000000   1.00000  32.736665 3122.06860  64.26759 #> [30,]    1.00000   1.000000   1.00000   1.000000 1364.95376  58.45803 #> [31,]    1.00000 120.198508 574.78753  53.526953    1.00000   1.00000 #> [32,]  796.11332   1.000000 100.35824   1.000000 1239.80143 315.18394 #> [33,]  216.24369  95.847576  69.58651  51.149474   76.47723   1.00000 #> [34,]  365.81695  45.995045   1.00000   1.000000  821.34736   1.00000 #> [35,]    1.00000   1.000000 199.07164   1.000000    1.00000   1.00000 #> [36,]  544.72275 114.168966   1.00000   1.000000    1.00000   1.00000 #> [37,]   58.10979   1.000000   1.00000   1.000000 1443.73127   1.00000 #> [38,]    1.00000   1.000000 277.08083 141.818912  538.93923   1.00000 #> [39,]  749.38225   1.000000   1.00000 172.397298    1.00000 109.99913 #> [40,]    1.00000   1.000000   1.00000   1.000000 3859.75540 162.86135 #> [41,]    1.00000 102.666061 534.01340   1.000000  561.40915   1.00000 #> [42,]  760.43696   1.000000   1.00000   1.000000    1.00000 130.04901 #> [43,]    1.00000   8.930577 172.82803   7.558633    1.00000 229.78510 #> [44,]  151.00134  26.193270 306.92326  10.579157    1.00000   1.00000 #> [45,]    1.00000   1.000000   1.00000  31.663417 1515.88706   1.00000 #> [46,]   63.69395 102.470566 134.04977   1.000000    1.00000 104.98964 #> [47,]    1.00000 131.899237 132.49391   1.000000 1145.81057  29.53101 #> [48,]  956.45163  49.656709 313.97560 130.686468    1.00000  88.53350 #> [49,]  369.96333   1.000000 146.06190   1.000000 1415.61365 226.61678 #> [50,]  176.40350   1.000000   1.00000  33.083878    1.00000  62.44786 #>                y         z  indicator #>  [1,] 100.000000 100.00000 100.000000 #>  [2,]  59.228365  42.89649  28.502036 #>  [3,]  41.230376 153.09207  19.766610 #>  [4,]  36.710466   1.00000   7.942748 #>  [5,] 122.784230   1.00000  12.267967 #>  [6,]   1.000000   1.00000   6.896343 #>  [7,]   1.000000 162.70082   6.728697 #>  [8,]  56.284614   1.00000   4.592307 #>  [9,]   1.000000 125.92040   9.439848 #> [10,]   7.036714   1.00000   5.626644 #> [11,]  70.483644   1.00000   5.904375 #> [12,]  71.626332  67.16126   6.900736 #> [13,]   1.000000   1.00000   9.284280 #> [14,]   1.000000  99.99237   8.369144 #> [15,]   6.998053  63.82710   8.984141 #> [16,] 101.076020   1.00000  12.820306 #> [17,]  40.507747  90.58142   7.123193 #> [18,] 136.256136 227.14503  17.395310 #> [19,]   1.000000   1.00000   5.297931 #> [20,] 107.033018   1.00000  10.146164 #> [21,]  83.959422  77.84705   6.330338 #> [22,]  58.199365 265.97442   8.707359 #> [23,]  39.431416   1.00000   7.424993 #> [24,]   1.000000   1.00000   9.730921 #> [25,]   1.000000   1.00000   4.393866 #> [26,]  21.811849   1.00000  12.804487 #> [27,]   4.648553   1.00000   6.033059 #> [28,]  89.685588  93.60815   3.937974 #> [29,]   1.000000  46.84329   9.385240 #> [30,]   1.000000 230.36703   4.877519 #> [31,]   1.000000  98.24635   7.257362 #> [32,]   1.000000   1.00000   8.157058 #> [33,]   1.000000  38.77631  11.887064 #> [34,]   1.000000  28.57198  12.088508 #> [35,]   1.000000  15.01343   3.448723 #> [36,]   1.000000 248.57982   8.274994 #> [37,]   1.000000   1.00000   7.177986 #> [38,]   1.000000 192.53611   5.272862 #> [39,]   1.000000  27.81953  13.540560 #> [40,]   1.000000  58.49652   6.280666 #> [41,]  62.137014  29.15650   5.830755 #> [42,] 168.606683   1.00000   7.520038 #> [43,]   1.000000  77.63637   8.988192 #> [44,] 141.978039 104.45120  15.525576 #> [45,]   7.894082 202.69464   8.743469 #> [46,]  10.985259 107.46570  10.036238 #> [47,]  30.885701 155.54817  10.892613 #> [48,]   1.000000   1.00000   8.847461 #> [49,]   1.000000 115.10932  14.701704 #> [50,]  86.378872   1.00000  13.828788"},{"path":"/reference/summarise_occDet.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise Occupancy model output — summarise_occDet","title":"Summarise Occupancy model output — summarise_occDet","text":"function reads summarises .rdata files output occDetModel sparta.","code":""},{"path":"/reference/summarise_occDet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise Occupancy model output — summarise_occDet","text":"","code":"summarise_occDet(input_dir, region = NULL, verbose = TRUE)"},{"path":"/reference/summarise_occDet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise Occupancy model output — summarise_occDet","text":"input_dir directory .rdata files located. output_dir arguement given occDetModel sparta creating output. region model output contains regional estimates specify region name extract estimates region (e.g.\"ENGLAND\"). NULL estimate based sites used instead. verbose TRUE progress printed screen.","code":""},{"path":"/reference/summarise_occDet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise Occupancy model output — summarise_occDet","text":"data.frame. row year, species         mean posterior predicted proportion sites occupied.","code":""},{"path":"/reference/trend_assessment.html","id":null,"dir":"Reference","previous_headings":"","what":"Assess trends for indicator — trend_assessment","title":"Assess trends for indicator — trend_assessment","text":"assessment covers indicator constituent species. assessment made indicator time period given, examining whether initial indicator value falls within credible interval final year. time period change species assessed reported.","code":""},{"path":"/reference/trend_assessment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assess trends for indicator — trend_assessment","text":"","code":"trend_assessment(   dat,   method = \"lambda\",   start_year = NULL,   end_year = NULL,   species_stat = \"mean\" )"},{"path":"/reference/trend_assessment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assess trends for indicator — trend_assessment","text":"dat object returned lambda_interpolation bma method indicator method used produce data. One \"lambda\" \"bma\". start_year (Optional) numeric value, defaults first year end_year (Optional) numeric value, defaults last year species_stat (Optional) character, statistic used average across species yearly change values arrive single value per species. can  either 'mean' (default) 'median'.","code":""},{"path":"/reference/trend_assessment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assess trends for indicator — trend_assessment","text":"Returns list two elements, summary species indicator assessments. plot species assessment returned device.","code":""},{"path":"/reference/trend_assessment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assess trends for indicator — trend_assessment","text":"","code":"### Running from an array #### set.seed(123) # number of species nsp = 50  # number of years nyr = 40  #number of iterations iter = 500  # Build a random set of data myArray <- array(data = rnorm(n = nsp*nyr*iter,                               mean = 0.5,                               sd = 0.1),                  dim = c(nsp, nyr, iter),                  dimnames = list(paste0('SP',1:nsp),                                  1:nyr,                                  1:iter))  # Ensure values are bounded by 0 and 1 myArray[myArray > 1] <- 1 myArray[myArray < 0] <- 0  # Run the lambda_indicator method on this data                 myIndicator <- lambda_indicator(myArray)  # Plot the trend stack trend_assessment(myIndicator) #> $species_assessment #>      percent_change_year  category #> SP1         0.0905194271 no change #> SP2        -0.0799339038 no change #> SP3        -0.0560302992 no change #> SP4         0.0506986293 no change #> SP5         0.0568966703 no change #> SP6         0.0081296028 no change #> SP7         0.0814661373 no change #> SP8        -0.0250134002 no change #> SP9        -0.0697988570 no change #> SP10        0.0795581466 no change #> SP11       -0.0753321163 no change #> SP12        0.0010294928 no change #> SP13        0.0365834217 no change #> SP14       -0.0813422894 no change #> SP15        0.0223639048 no change #> SP16       -0.1084968105 no change #> SP17       -0.0508159392 no change #> SP18        0.0082710499 no change #> SP19       -0.0005364494 no change #> SP20        0.0224533381 no change #> SP21       -0.0743542872 no change #> SP22        0.0235321974 no change #> SP23       -0.1372121637 no change #> SP24        0.0068900108 no change #> SP25       -0.0717393802 no change #> SP26        0.0649905351 no change #> SP27        0.0496135655 no change #> SP28        0.0460645899 no change #> SP29       -0.0154301373 no change #> SP30       -0.0820871270 no change #> SP31       -0.0122093641 no change #> SP32       -0.0804416837 no change #> SP33        0.1000944876 no change #> SP34        0.0491616761 no change #> SP35        0.0457235228 no change #> SP36       -0.0423739548 no change #> SP37        0.0445838358 no change #> SP38        0.0195071361 no change #> SP39       -0.0479727135 no change #> SP40        0.0294197844 no change #> SP41       -0.0266787063 no change #> SP42       -0.0291441558 no change #> SP43        0.0172679059 no change #> SP44       -0.0066940954 no change #> SP45        0.0442883770 no change #> SP46       -0.2454249077 no change #> SP47        0.0190180208 no change #> SP48       -0.1036430275 no change #> SP49       -0.0218004687 no change #> SP50       -0.0117518859 no change #>  #> $indicator_asssessment #>   start_index end_lower end_upper assessment #> 1         100  84.59769  116.2142     stable #>"}]
